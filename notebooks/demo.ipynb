{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6f79b15d96f18b48",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2023-12-13T11:12:51.269813516Z",
     "start_time": "2023-12-13T11:12:46.424713911Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-13 12:12:48.323190: E tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:9342] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2023-12-13 12:12:48.323225: E tensorflow/compiler/xla/stream_executor/cuda/cuda_fft.cc:609] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2023-12-13 12:12:48.323262: E tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:1518] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2023-12-13 12:12:48.330437: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import mlflow\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import plotly.graph_objects as go\n",
    "from dash.dependencies import State\n",
    "from mlflow.tracking import MlflowClient\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "from src.functions import load_stations_from_path, preprocces, \\\n",
    "    create_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "test_path = '../data/labeled_benchmark/test'\n",
    "testing_stations = {station.iloc[0]['station_code']: station for station in load_stations_from_path(test_path)}\n",
    "\n",
    "for station_code, df in testing_stations.items():\n",
    "    df['measure_date'] = pd.to_datetime(df['measure_date'])\n",
    "    df['year'] = df['measure_date'].dt.year\n",
    "    df['month'] = df['measure_date'].dt.month\n",
    "    df['met_year'] = df['year']\n",
    "    df.loc[df['month'] <= 5, 'met_year'] = df['met_year'] - 1\n",
    "\n",
    "def scale(data, scaler_class):\n",
    "    features_to_scale = ['HS', 'TSS_30MIN_MEAN', 'RSWR_30MIN_MEAN', 'TA_30MIN_MEAN', 'VW_30MIN_MEAN']\n",
    "    scaled = {}\n",
    "    for station_code, df in data.items():\n",
    "        scaler = scaler_class()\n",
    "        scaled[station_code] = df.copy()\n",
    "        scaled[station_code][features_to_scale] = scaler.fit_transform(scaled[station_code][features_to_scale])\n",
    "\n",
    "    return scaled\n",
    "\n",
    "# testing_stations_zscore = scale(testing_stations, StandardScaler)\n",
    "testing_stations_minmax = scale(testing_stations, MinMaxScaler)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-13T11:12:51.634086126Z",
     "start_time": "2023-12-13T11:12:51.282284838Z"
    }
   },
   "id": "10e88df63fd31e3f"
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "data": {
      "text/plain": "Downloading artifacts:   0%|          | 0/11 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "899fe94eec38403ba445ad775d24c190"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023/12/13 12:12:53 INFO mlflow.store.artifact.artifact_repo: The progress bar can be disabled by setting the environment variable MLFLOW_ENABLE_ARTIFACTS_PROGRESS_BAR to false\n",
      "2023-12-13 12:12:54.380960: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-12-13 12:12:54.403465: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-12-13 12:12:54.407992: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-12-13 12:12:54.413267: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-12-13 12:12:54.413682: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-12-13 12:12:54.413986: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-12-13 12:12:54.594048: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-12-13 12:12:54.594505: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-12-13 12:12:54.594922: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-12-13 12:12:54.595184: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1886] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 148 MB memory:  -> device: 0, name: NVIDIA GeForce GTX 1050 Ti with Max-Q Design, pci bus id: 0000:01:00.0, compute capability: 6.1\n",
      "2023-12-13 12:12:54.792473: I tensorflow/tsl/platform/default/subprocess.cc:304] Start cannot spawn child process: No such file or directory\n"
     ]
    }
   ],
   "source": [
    "mlflow.set_tracking_uri('http://localhost:5000')\n",
    "\n",
    "experiment_name = 'Benchmark'\n",
    "run_name = '2023-12-12_16:24:28_truncate_all_if_one_missing'\n",
    "\n",
    "client = MlflowClient()\n",
    "experiment = client.get_experiment_by_name('Benchmark')\n",
    "runs = client.search_runs(experiment_ids=[experiment.experiment_id], filter_string=f\"tags.mlflow.runName = '{run_name}'\")\n",
    "selected_run = runs[0] if len(runs) > 0 else None\n",
    "run_id = selected_run.info.run_id\n",
    "model_uri = f\"runs:/{run_id}/model\"\n",
    "model = mlflow.tensorflow.load_model(model_uri)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-13T11:12:56.922133287Z",
     "start_time": "2023-12-13T11:12:52.990487626Z"
    }
   },
   "id": "27ccb72c6dd89b2a"
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-13 12:13:09.237986: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:442] Loaded cuDNN version 8700\n"
     ]
    }
   ],
   "source": [
    "SEQUENCE_LENGTH = 90\n",
    "TARGET_START_INDEX = SEQUENCE_LENGTH - 1\n",
    "FEATURE_COLUMNS = [\n",
    "    'HS',\n",
    "    'day_sin',\n",
    "    'day_cos',\n",
    "    'month_sin',\n",
    "    'month_cos',\n",
    "    'TSS_30MIN_MEAN',\n",
    "    'RSWR_30MIN_MEAN',\n",
    "    'TA_30MIN_MEAN',\n",
    "    'VW_30MIN_MEAN'\n",
    "]\n",
    "TARGET_COLUMN = 'no_snow'\n",
    "DATASET_BATCH_SIZE = 64\n",
    "\n",
    "# Values taken from the original dataset\n",
    "train_mean = np.array([89.38116858114648, 0.0011084782603573208, -0.017600892344483886, -0.0054428754913079195, 0.005005952200941785, -1.2958664264976802, 86.82415770740349, 1.733119096445471, 1.8837531498159192])\n",
    "train_std = np.array([105.46005140685408, 0.7132728403500057, 0.7006645667270192, 0.7042157273701615, 0.7099475507870721, 9.356596509160058, 84.9729233123369, 7.32290085363148, 1.6545282612533645])\n",
    "\n",
    "testing_stations_real = {}\n",
    "for station_code, df in testing_stations.items():\n",
    "    testing_stations_real[station_code] = preprocces(df.copy())\n",
    "    testing_stations_real[station_code][FEATURE_COLUMNS] -= train_mean\n",
    "    testing_stations_real[station_code][FEATURE_COLUMNS] /= train_std\n",
    "\n",
    "evaluate = False\n",
    "all_evaluation_results = np.empty((0, 5), float)\n",
    "\n",
    "for station_code, df in testing_stations_real.items():\n",
    "    station = preprocces(df)\n",
    "\n",
    "    features = station[FEATURE_COLUMNS]\n",
    "    targets = station[TARGET_COLUMN]\n",
    "\n",
    "    test_dataset = create_dataset(\n",
    "        features, targets, SEQUENCE_LENGTH, TARGET_START_INDEX, DATASET_BATCH_SIZE, shuffle=False\n",
    "    )\n",
    "    \n",
    "    testing_stations_minmax[station_code]['preds'] = np.concatenate([np.full(SEQUENCE_LENGTH - 1, False), model.predict(test_dataset, verbose=0).reshape((-1,)) > 0.5])\n",
    "    if evaluate:\n",
    "        evaluation_results = model.evaluate(test_dataset, verbose=0)\n",
    "        precision = evaluation_results[2]\n",
    "        recall = evaluation_results[3]\n",
    "        f1_score = 2 * (precision * recall) / (precision + recall) if (precision + recall) != 0 else 0\n",
    "        print(f\"station: {station_code}, loss: {evaluation_results[0]:.4f} - accuracy: {evaluation_results[1]:.4f} - recall_2: {evaluation_results[2]:.4f} - precision_2: {evaluation_results[3]:.4f}\")\n",
    "        all_evaluation_results = np.append(all_evaluation_results, [evaluation_results + [f1_score]], axis=0)\n",
    "if evaluate: \n",
    "    print('test_avg_loss', f\"{np.mean(all_evaluation_results[:, 0]):.4f}\")\n",
    "    print('test_avg_accuracy', f\"{np.mean(all_evaluation_results[:, 1]):.4f}\")\n",
    "    print('test_avg_precision', f\"{np.mean(all_evaluation_results[:, 2]):.4f}\")\n",
    "    print('test_avg_recall', f\"{np.mean(all_evaluation_results[:, 3]):.4f}\")\n",
    "    print('test_avg_f1_score', f\"{np.mean(all_evaluation_results[:, 4]):.4f}\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-13T11:13:15.735871488Z",
     "start_time": "2023-12-13T11:13:07.639274938Z"
    }
   },
   "id": "782ea2b2de8b8a55"
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dash app running on http://127.0.0.1:8050/\n"
     ]
    }
   ],
   "source": [
    "import dash\n",
    "from dash import dcc, html, Input, Output\n",
    "import plotly.graph_objs as go\n",
    "\n",
    "app = dash.Dash(__name__)\n",
    "\n",
    "features_to_display =[\n",
    "    'HS',\n",
    "    'TSS_30MIN_MEAN',\n",
    "    'RSWR_30MIN_MEAN',\n",
    "    'TA_30MIN_MEAN',\n",
    "    'VW_30MIN_MEAN',\n",
    "    'preds',\n",
    "    'no_snow'\n",
    "] \n",
    "\n",
    "def find_consecutive_date_ranges(dates):\n",
    "    if len(dates) == 0:\n",
    "        return []\n",
    "\n",
    "    sorted_dates = sorted(dates)  # Ensure dates are sorted\n",
    "    ranges = []\n",
    "    start = end = sorted_dates[0]\n",
    "\n",
    "    for date in sorted_dates[1:]:\n",
    "        if (date - end).days <= 1:\n",
    "            end = date\n",
    "        else:\n",
    "            ranges.append((start, end))\n",
    "            start = end = date\n",
    "    ranges.append((start, end))  # Add the last range\n",
    "    return ranges\n",
    "\n",
    "\n",
    "app.layout = html.Div([\n",
    "    dcc.Graph(id='time-series-chart', figure=go.Figure()),\n",
    "\n",
    "    html.Div([\n",
    "        dcc.Dropdown(\n",
    "            id='station-dropdown',\n",
    "            options=[{'label': i, 'value': i} for i in testing_stations_minmax.keys()],\n",
    "            value=list(testing_stations_minmax.keys())[0],\n",
    "            style={'width': '48%', 'display': 'inline-block'}\n",
    "        ),\n",
    "        dcc.Dropdown(\n",
    "            id='year-dropdown',\n",
    "            options=[{'label': i, 'value': i} for i in range(1990, 2023)],\n",
    "            value=2006,\n",
    "            style={'width': '48%', 'display': 'inline-block'}\n",
    "        )\n",
    "    ]),\n",
    "\n",
    "    html.Div([\n",
    "        dcc.Checklist(\n",
    "            id='feature-checklist',\n",
    "            options=[{'label': feature, 'value': feature} for feature in features_to_display],\n",
    "            value=['HS', 'no_snow', 'preds'],\n",
    "            style={'padding': 10}\n",
    "        )\n",
    "    ])\n",
    "])\n",
    "\n",
    "@app.callback(\n",
    "    Output('year-dropdown', 'options'),\n",
    "    [Input('station-dropdown', 'value')]\n",
    ")\n",
    "def update_year_options(selected_station):\n",
    "    selected_station_df = testing_stations_minmax[selected_station]\n",
    "\n",
    "    years = sorted(selected_station_df['measure_date'].dt.year.unique())\n",
    "    year_options = [{'label': year, 'value': year} for year in years]\n",
    "\n",
    "    return year_options\n",
    "\n",
    "# Callback to update the graph\n",
    "@app.callback(\n",
    "    Output('time-series-chart', 'figure'),\n",
    "    [Input('station-dropdown', 'value'),\n",
    "     Input('year-dropdown', 'value'),\n",
    "     Input('feature-checklist', 'value')],\n",
    "    [State('time-series-chart', 'figure')]\n",
    ")\n",
    "def update_graph(selected_station, selected_met_year, selected_features, existing_figure):\n",
    "    selected_station_df = testing_stations_minmax[selected_station]\n",
    "    filtered_df = selected_station_df[selected_station_df['met_year'] == selected_met_year]\n",
    "\n",
    "    existing_figure['layout']['shapes'] = []\n",
    "    data = []\n",
    "    shapes = []\n",
    "    for feature in selected_features:\n",
    "        if feature != 'no_snow' and feature != 'preds':\n",
    "            data.append(go.Scatter(x=filtered_df['measure_date'], y=filtered_df[feature], name=feature))\n",
    "\n",
    "    if 'no_snow' in selected_features:\n",
    "        no_snow_data = filtered_df[filtered_df['no_snow']]['measure_date'].sort_values()\n",
    "        if not no_snow_data.empty:\n",
    "            date_ranges = find_consecutive_date_ranges(no_snow_data)\n",
    "\n",
    "            for start, end in date_ranges:\n",
    "                shapes.append({\n",
    "                    'type': 'rect',\n",
    "                    'x0': start,\n",
    "                    'y0': 0,\n",
    "                    'x1': end,\n",
    "                    'y1': 1,\n",
    "                    'fillcolor': 'red',\n",
    "                    'opacity': 0.2,\n",
    "                    'line': {'width': 0},\n",
    "                })\n",
    "\n",
    "    if 'preds' in selected_features:\n",
    "        preds_data = filtered_df[filtered_df['preds']]\n",
    "        data.append(\n",
    "            go.Scatter(x=preds_data['measure_date'], y=preds_data['HS'], mode='markers', name='Predictions', marker=dict(color='green', size=10))\n",
    "        )\n",
    "\n",
    "    figure = go.Figure(data=data, layout=existing_figure['layout'])\n",
    "    figure.update_layout(\n",
    "        title='Normalized Time Series Data',\n",
    "        xaxis_title='Date',\n",
    "        yaxis_title='Normalized Value',\n",
    "        shapes=shapes,\n",
    "        template=\"plotly_white\",\n",
    "        showlegend=True\n",
    "    )\n",
    "    \n",
    "    return figure\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    app.run(jupyter_mode=\"external\", debug=True)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-13T11:13:22.504345631Z",
     "start_time": "2023-12-13T11:13:22.461891871Z"
    }
   },
   "id": "f083172e1259a269"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
