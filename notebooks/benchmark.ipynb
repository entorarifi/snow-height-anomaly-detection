{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": [],
    "ExecuteTime": {
     "end_time": "2023-11-02T09:53:34.822461511Z",
     "start_time": "2023-11-02T09:53:30.214217218Z"
    }
   },
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import socket"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-02T09:53:35.233651016Z",
     "start_time": "2023-11-02T09:53:35.231804526Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]"
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gpus = tf.config.list_physical_devices('GPU')\n",
    "gpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-02T09:53:36.461254802Z",
     "start_time": "2023-11-02T09:53:36.460589019Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 Physical GPUs, 1 Logical GPUs\n"
     ]
    }
   ],
   "source": [
    "if gpus:\n",
    "    try:\n",
    "        for gpu in gpus:\n",
    "            tf.config.experimental.set_memory_growth(gpu, True)\n",
    "        logical_gpus = tf.config.list_logical_devices('GPU')\n",
    "        print(len(gpus), \"Physical GPUs,\", len(logical_gpus), \"Logical GPUs\")\n",
    "    except RuntimeError as e:\n",
    "        print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": [],
    "ExecuteTime": {
     "end_time": "2023-11-02T09:53:39.324424545Z",
     "start_time": "2023-11-02T09:53:39.224448752Z"
    }
   },
   "outputs": [],
   "source": [
    "if socket.gethostname() == 'pop-os':\n",
    "    df = pd.read_csv('../data/merged_labeled_daily.csv')\n",
    "else:\n",
    "    df = pd.read_csv('./data/merged.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-02T09:53:40.458652756Z",
     "start_time": "2023-11-02T09:53:40.249948880Z"
    }
   },
   "outputs": [],
   "source": [
    "df = df.drop(columns=df.columns[:2])\n",
    "df['measure_date'] = pd.to_datetime(df['measure_date'])\n",
    "df['year'] = df['measure_date'].dt.year\n",
    "df['month'] = df['measure_date'].dt.month\n",
    "df['day'] = df['measure_date'].dt.day\n",
    "df['weekday'] = df['measure_date'].dt.weekday\n",
    "df['month_sin'] = np.sin(2 * np.pi * df['month'] / 12)\n",
    "df['month_cos'] = np.cos(2 * np.pi * df['month'] / 12)\n",
    "df['day_sin'] = np.sin(2 * np.pi * df['day'] / 31)\n",
    "df['day_cos'] = np.cos(2 * np.pi * df['day'] / 31)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "num_train_stations = 15\n",
    "stations = df['station_code'].unique()\n",
    "\n",
    "train_val_end_index = df[df['station_code'] == stations[num_train_stations - 1]].index[-1] + 1\n",
    "\n",
    "num_train_samples = int(0.7 * train_val_end_index)\n",
    "num_val_samples = train_val_end_index - num_train_samples\n",
    "num_test_samples = len(df) - train_val_end_index\n",
    "\n",
    "print(\"Train length: %s\" % num_train_samples)\n",
    "print(\"Validation length: %s\" % num_val_samples)\n",
    "print(\"Test length: %s\" % num_test_samples)\n",
    "\n",
    "total = num_train_samples + num_val_samples + num_test_samples\n",
    "print(total, len(df), total == len(df))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [],
   "source": [
    "def get_features_and_targets(df, num_train_samples=None, feature_cols=None, target_cols=None, scale=True, mean=None, std=None):\n",
    "    if num_train_samples is None:\n",
    "        num_train_samples = len(df)\n",
    "        \n",
    "    if feature_cols is None:\n",
    "        feature_cols = ['HS', 'day_sin', 'day_cos', 'month_sin', 'month_cos']\n",
    "\n",
    "    if target_cols is None:\n",
    "        target_cols = ['no_snow']\n",
    "        \n",
    "    if (mean is None) ^ (std is None):\n",
    "        raise Exception('mean and std must both be set or unset')\n",
    "\n",
    "    feature_cols = df[feature_cols].values\n",
    "    target_cols = df[target_cols].values\n",
    "    \n",
    "    if not scale:\n",
    "        return feature_cols, target_cols, None, None\n",
    "    \n",
    "    if mean is None:\n",
    "        mean = feature_cols[:num_train_samples].mean(axis=0)\n",
    "        feature_cols -= mean\n",
    "        std = feature_cols[:num_train_samples].std(axis=0)\n",
    "        feature_cols /= std\n",
    "    else:\n",
    "        feature_cols = (feature_cols - mean) / std\n",
    "\n",
    "    return feature_cols, target_cols, mean, std"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-02T10:26:20.385066190Z",
     "start_time": "2023-11-02T10:26:20.381584495Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "features, targets, _, _ = get_features_and_targets(df, num_train_samples)\n",
    "\n",
    "print(targets[:3])\n",
    "print(features[:3])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sequence_debugging():\n",
    "    int_sequence = np.arange(30)\n",
    "\n",
    "    train_end_index = int(0.5 * len(int_sequence))\n",
    "    val_end_index = int(0.75 * len(int_sequence))\n",
    "\n",
    "    sequence_length = 3\n",
    "    target_start_idx = sequence_length - 1\n",
    "\n",
    "    train_dataset = keras.utils.timeseries_dataset_from_array(\n",
    "        data=int_sequence,\n",
    "        targets=int_sequence[target_start_idx:],\n",
    "        sequence_length=sequence_length,\n",
    "        start_index=0,\n",
    "        end_index=train_end_index\n",
    "    )\n",
    "\n",
    "    val_dataset = keras.utils.timeseries_dataset_from_array(\n",
    "        data=int_sequence,\n",
    "        targets=int_sequence[target_start_idx:],\n",
    "        sequence_length=sequence_length,\n",
    "        start_index=train_end_index,\n",
    "        end_index=val_end_index\n",
    "    )\n",
    "\n",
    "    test_dataset = keras.utils.timeseries_dataset_from_array(\n",
    "        data=int_sequence,\n",
    "        targets=int_sequence[target_start_idx:],\n",
    "        sequence_length=sequence_length,\n",
    "        start_index=val_end_index\n",
    "    )\n",
    "\n",
    "    print(\"Train:\")\n",
    "    for inputs, targets in train_dataset:\n",
    "        for i in range(inputs.shape[0]):\n",
    "            print([int(x) for x in inputs[i]], int(targets[i]))\n",
    "\n",
    "            \n",
    "    print(\"\\nVal:\")\n",
    "    for inputs, targets in val_dataset:\n",
    "        for i in range(inputs.shape[0]):\n",
    "            print([int(x) for x in inputs[i]], int(targets[i]))\n",
    "\n",
    "    print(\"\\nTest:\")\n",
    "    for inputs, targets in test_dataset:\n",
    "        for i in range(inputs.shape[0]):\n",
    "            print([int(x) for x in inputs[i]], int(targets[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-02T09:53:50.899557800Z",
     "start_time": "2023-11-02T09:53:50.899127998Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from tensorflow import keras\n",
    "\n",
    "def create_dataset(features, targets, start_index=0, end_index=None, sequence_length=30, batch_size=128, shuffle=False):\n",
    "    target_start_idx = sequence_length - 1\n",
    "    \n",
    "    return keras.utils.timeseries_dataset_from_array(\n",
    "        data=features,\n",
    "        targets=targets[target_start_idx:],\n",
    "        sequence_length=sequence_length,\n",
    "        sequence_stride=1,\n",
    "        sampling_rate=1,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=shuffle,\n",
    "        start_index=start_index,\n",
    "        end_index=end_index\n",
    "    )\n",
    "\n",
    "# train_dataset = create_dataset(features, targets, start_index=0, end_index=num_train_samples, shuffle=True)\n",
    "# val_dataset = create_dataset(features, targets, start_index=num_train_samples, end_index=num_train_samples + num_val_samples, shuffle=True)\n",
    "# test_dataset = create_dataset(features, targets, start_index=num_train_samples + num_val_samples, end_index=(len(df) - 1), shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "class MonteCarloDropout(keras.layers.Dropout):\n",
    "    def call(self, inputs, training=None):\n",
    "        return super().call(inputs, training=True)\n",
    "    \n",
    "def create_network(architecture, input_shape, dropout_rate=0.5, summary=True):\n",
    "    arch_split = architecture.split('-')\n",
    "    dense = True\n",
    "    bidirectional = False\n",
    "    layers = []\n",
    "\n",
    "    digits_pattern = re.compile(r\"\\d+\")\n",
    "    \n",
    "    if 'l' in arch_split[0]:\n",
    "        rnn_layer = 'LSTM'\n",
    "    elif 'g' in arch_split[0]:\n",
    "        rnn_layer = 'GRU'\n",
    "    else:\n",
    "        raise Exception('rnn_layers must be one of [LSTM, GRU]')\n",
    "\n",
    "    if 'b' in arch_split[0]:\n",
    "        bidirectional = True\n",
    "        \n",
    "    for i, layer in enumerate(reversed(arch_split)):\n",
    "        no_units = int(digits_pattern.findall(layer)[0])\n",
    "\n",
    "        if dense:\n",
    "            activation = 'sigmoid' if i == 0 else 'relu'\n",
    "            layers.append(keras.layers.Dense(no_units, activation=activation))\n",
    "        else:\n",
    "            args = {\n",
    "                'units': no_units,\n",
    "            }\n",
    "\n",
    "            if '(d)' not in arch_split[-i]:\n",
    "                args['return_sequences'] = True\n",
    "\n",
    "            if i == len(arch_split) - 1:\n",
    "                args['input_shape'] = input_shape\n",
    "                \n",
    "            current_layer = keras.layers.LSTM(**args) if rnn_layer == 'LSTM' else keras.layers.GRU(**args)\n",
    "            \n",
    "            if bidirectional:\n",
    "                current_layer = keras.layers.Bidirectional(current_layer)\n",
    "            \n",
    "            layers.extend([\n",
    "                MonteCarloDropout(dropout_rate),\n",
    "                current_layer\n",
    "            ])\n",
    "            \n",
    "        if '(d)' in layer:\n",
    "            dense = False\n",
    "            \n",
    "    layers.reverse()\n",
    "    \n",
    "    if summary:\n",
    "        for layer in layers:\n",
    "            layer_type = str(type(layer))\n",
    "\n",
    "            if 'Dense' in str(type(layer)):\n",
    "                print(type(layer), layer.units, layer.activation)\n",
    "            elif 'Bidirectional' in str(type(layer)):\n",
    "                print(type(layer), layer.layer, layer.layer.units, layer.layer.activation, layer.layer.return_sequences)\n",
    "            elif 'LSTM' in str(type(layer)):\n",
    "                print(type(layer), layer.units, layer.activation, layer.return_sequences)\n",
    "            elif 'GRU' in str(type(layer)):\n",
    "                print(type(layer), layer.units, layer.activation, layer.return_sequences)\n",
    "            elif 'Dropout' in layer_type:\n",
    "                print(type(layer), layer.rate)\n",
    "\n",
    "    return layers\n",
    "\n",
    "# arch = \"128(gb)-64-8(d)-1\"\n",
    "# input_shape = (sequence_length, features.shape[-1])\n",
    "# network = create_network(arch, input_shape)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-02T09:53:53.003488544Z",
     "start_time": "2023-11-02T09:53:52.993607202Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "arch = \"128(l)-64-8(d)-1\"\n",
    "sequence_length = 30\n",
    "input_shape = (sequence_length, features.shape[-1])\n",
    "epochs = 10\n",
    "model_batch_size = 64\n",
    "checkpoint_name = 'snow_height_anomaly_multi_vars_gru.keras'\n",
    "current_time = datetime.now().strftime('%Y-%m-%d_%H-%M-%S')\n",
    "model_name = f\"{current_time}_arch-{arch}_epochs-{epochs}_batch-{model_batch_size}_seq-{sequence_length}_num-train-stations-{num_train_stations}\"\n",
    "log_dir = f\"./logs/{model_name}\"\n",
    "\n",
    "network = create_network(arch, input_shape)\n",
    "model = keras.Sequential(network)\n",
    "model.compile(\n",
    "    optimizer='adam',\n",
    "    metrics='accuracy',\n",
    "    loss='binary_crossentropy'\n",
    ")\n",
    "\n",
    "history = model.fit(\n",
    "    train_dataset,\n",
    "    epochs=epochs,\n",
    "    batch_size=model_batch_size,\n",
    "    validation_data=val_dataset,\n",
    "    # callbacks=[\n",
    "        # keras.callbacks.ModelCheckpoint(checkpoint_name, save_best_only=True),\n",
    "        # keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1) \n",
    "    # ]\n",
    ")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-02T09:53:55.920921397Z",
     "start_time": "2023-11-02T09:53:55.916809329Z"
    }
   },
   "outputs": [],
   "source": [
    "def plot_keras_history(history):\n",
    "    # Plot training & validation loss values\n",
    "    plt.figure(figsize=(12, 5))\n",
    "    \n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(history.history['loss'])\n",
    "    plt.plot(history.history['val_loss'])\n",
    "    plt.title('Model loss')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.legend(['Train', 'Validation'], loc='upper left')\n",
    "\n",
    "    # Plot training & validation accuracy values\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.plot(history.history['accuracy'])\n",
    "    plt.plot(history.history['val_accuracy'])\n",
    "    plt.title('Model accuracy')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.legend(['Train', 'Validation'], loc='upper left')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# plot_keras_history(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "model.evaluate(test_dataset)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-02T09:53:58.299677731Z",
     "start_time": "2023-11-02T09:53:58.297246722Z"
    }
   },
   "outputs": [],
   "source": [
    "def plot_data(dfs, y='HS', target='no_snow', predictions=None):\n",
    "    if not isinstance(dfs, list):\n",
    "        dfs = [dfs]\n",
    "\n",
    "    if not isinstance(predictions, list):\n",
    "        predictions = [predictions] if predictions else []\n",
    "\n",
    "    if not isinstance(y, list):\n",
    "        y = [y] * len(dfs)\n",
    "\n",
    "    if not isinstance(target, list):\n",
    "        target = [target] * len(dfs)\n",
    "\n",
    "    if len(predictions):\n",
    "        rows = len(dfs) * 2\n",
    "    else:\n",
    "        rows = len(dfs)\n",
    "\n",
    "    fig, axes = plt.subplots(rows, 1, figsize=(20, 5 * rows))\n",
    "\n",
    "    if not isinstance(axes, np.ndarray):\n",
    "        axes = [axes]\n",
    "\n",
    "    for i, df in enumerate(dfs):\n",
    "        plot_df = df.copy()\n",
    "        plot_df.index = pd.to_datetime(plot_df['measure_date'])\n",
    "        station_code = plot_df['station_code'].iloc[0]\n",
    "\n",
    "        # Plot original data\n",
    "        ax = axes[2 * i] if len(predictions) else axes[i]\n",
    "        ax.set_xlabel('Date')\n",
    "        ax.set_ylabel(y[i])\n",
    "        ax.set_title(f'Station: {station_code} | Original Data with Anomalies Highlighted')\n",
    "        ax.plot(plot_df.index, plot_df[y[i]], label='Data', marker='o', linestyle='-', ms=4)\n",
    "        ax.scatter(plot_df[plot_df[target[i]]].index, plot_df[plot_df[target[i]]][y[i]], color='red', label='Anomalies', zorder=5, s=20)\n",
    "        ax.legend()\n",
    "\n",
    "        # Plot predictions\n",
    "        if len(predictions):\n",
    "            ax = axes[2 * i + 1]\n",
    "            ax.set_xlabel('Date')\n",
    "            ax.set_ylabel(y[i])\n",
    "            ax.set_title(f'Station: {station_code} | Predicted Data with Anomalies Highlighted')\n",
    "            ax.plot(plot_df.index, plot_df[y[i]], label='Data', marker='o', linestyle='-', ms=4)\n",
    "            ax.scatter(plot_df[predictions[i]].index, plot_df[predictions[i]][y[i]], color='green', label='Predicted Anomalies', zorder=5, s=20)\n",
    "            ax.legend()\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "test_stations = df[train_val_end_index:]['station_code'].unique()\n",
    "test_stations = [(df[df['station_code'] == station].index.values[[0, -1]], df[df['station_code'] == station][sequence_length:]) for station in test_stations]\n",
    "\n",
    "predictions = [model.predict(create_dataset(features, targets, station[0][0], station[0][1])).reshape((-1,)) > 0.5 for station in test_stations]\n",
    "\n",
    "plot_data(\n",
    "    [station[1] for station in test_stations],\n",
    "    predictions=predictions\n",
    ")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [],
   "source": [
    "def predict_with_uncertainty(model, x, n_iter=100):\n",
    "    preds = np.array([model.predict(x, verbose=0) for _ in range(n_iter)])\n",
    "    uncertainty = np.std(preds, axis=0)\n",
    "    scaled_uncertainty = (uncertainty - uncertainty.min()) / (uncertainty.max() - uncertainty.min())\n",
    "    return scaled_uncertainty.mean()\n",
    "\n",
    "# uncertainties = [predict_with_uncertainty(model, create_dataset(station[0][0], station[0][1]), n_iter=20) for station in test_stations]\n",
    "# accuracy = [model.evaluate(create_dataset(station[0][0], station[0][1]))[1] for station in test_stations]\n",
    "# \n",
    "# print(np.corrcoef(uncertainties, accuracy))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-02T09:54:55.359947150Z",
     "start_time": "2023-11-02T09:54:55.349876975Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'keras.layers.rnn.lstm.LSTM'> 128 <function tanh at 0x7f9a3302d040> True\n",
      "<class '__main__.MonteCarloDropout'> 0.5\n",
      "<class 'keras.layers.rnn.lstm.LSTM'> 64 <function tanh at 0x7f9a3302d040> False\n",
      "<class '__main__.MonteCarloDropout'> 0.5\n",
      "<class 'keras.layers.core.dense.Dense'> 8 <function relu at 0x7f9a33029ca0>\n",
      "<class 'keras.layers.core.dense.Dense'> 1 <function sigmoid at 0x7f9a3302d1f0>\n",
      "====================================================\n",
      "Active Learning Iteration #0\n",
      "Current Training Stations: ['AMD2']\n",
      "Epoch 1/10\n",
      "58/58 [==============================] - 7s 46ms/step - loss: 0.2352 - accuracy: 0.9150 - val_loss: 0.1331 - val_accuracy: 0.9479\n",
      "Epoch 2/10\n",
      "58/58 [==============================] - 2s 27ms/step - loss: 0.1621 - accuracy: 0.9296 - val_loss: 0.1250 - val_accuracy: 0.9457\n",
      "Epoch 3/10\n",
      "58/58 [==============================] - 2s 33ms/step - loss: 0.1532 - accuracy: 0.9315 - val_loss: 0.1318 - val_accuracy: 0.9319\n",
      "Epoch 4/10\n",
      "58/58 [==============================] - 2s 29ms/step - loss: 0.1466 - accuracy: 0.9323 - val_loss: 0.1146 - val_accuracy: 0.9594\n",
      "Epoch 5/10\n",
      "58/58 [==============================] - 2s 27ms/step - loss: 0.1440 - accuracy: 0.9367 - val_loss: 0.1075 - val_accuracy: 0.9610\n",
      "Epoch 6/10\n",
      "58/58 [==============================] - 2s 26ms/step - loss: 0.1411 - accuracy: 0.9380 - val_loss: 0.1098 - val_accuracy: 0.9638\n",
      "Epoch 7/10\n",
      "58/58 [==============================] - 2s 27ms/step - loss: 0.1369 - accuracy: 0.9394 - val_loss: 0.1067 - val_accuracy: 0.9660\n",
      "Epoch 8/10\n",
      "58/58 [==============================] - 2s 28ms/step - loss: 0.1306 - accuracy: 0.9392 - val_loss: 0.1009 - val_accuracy: 0.9698\n",
      "Epoch 9/10\n",
      "58/58 [==============================] - 2s 27ms/step - loss: 0.1305 - accuracy: 0.9413 - val_loss: 0.1054 - val_accuracy: 0.9616\n",
      "Epoch 10/10\n",
      "58/58 [==============================] - 2s 27ms/step - loss: 0.1304 - accuracy: 0.9432 - val_loss: 0.1048 - val_accuracy: 0.9649\n",
      "Evaluation model on out of sample data...\n",
      "334/334 [==============================] - 7s 19ms/step - loss: 0.2808 - accuracy: 0.9121\n",
      "Calculating uncertainty scores...\n",
      "Most uncertain FLU2\n",
      "====================================================\n",
      "Active Learning Iteration #1\n",
      "Current Training Stations: ['AMD2', 'FLU2']\n",
      "Epoch 1/10\n",
      "102/102 [==============================] - 2s 22ms/step - loss: 0.1525 - accuracy: 0.9427 - val_loss: 0.1429 - val_accuracy: 0.9438\n",
      "Epoch 2/10\n",
      "102/102 [==============================] - 2s 21ms/step - loss: 0.1501 - accuracy: 0.9437 - val_loss: 0.1482 - val_accuracy: 0.9450\n",
      "Epoch 3/10\n",
      "102/102 [==============================] - 2s 22ms/step - loss: 0.1435 - accuracy: 0.9462 - val_loss: 0.1363 - val_accuracy: 0.9515\n",
      "Epoch 4/10\n",
      "102/102 [==============================] - 2s 21ms/step - loss: 0.1432 - accuracy: 0.9455 - val_loss: 0.1330 - val_accuracy: 0.9506\n",
      "Epoch 5/10\n",
      "102/102 [==============================] - 2s 22ms/step - loss: 0.1402 - accuracy: 0.9455 - val_loss: 0.1491 - val_accuracy: 0.9422\n",
      "Epoch 6/10\n",
      "102/102 [==============================] - 3s 24ms/step - loss: 0.1349 - accuracy: 0.9491 - val_loss: 0.1370 - val_accuracy: 0.9484\n",
      "Epoch 7/10\n",
      "102/102 [==============================] - 2s 23ms/step - loss: 0.1320 - accuracy: 0.9500 - val_loss: 0.1494 - val_accuracy: 0.9410\n",
      "Epoch 8/10\n",
      "102/102 [==============================] - 3s 26ms/step - loss: 0.1320 - accuracy: 0.9491 - val_loss: 0.1631 - val_accuracy: 0.9317\n",
      "Epoch 9/10\n",
      "102/102 [==============================] - 3s 28ms/step - loss: 0.1285 - accuracy: 0.9498 - val_loss: 0.1566 - val_accuracy: 0.9354\n",
      "Epoch 10/10\n",
      "102/102 [==============================] - 3s 27ms/step - loss: 0.1257 - accuracy: 0.9509 - val_loss: 0.1365 - val_accuracy: 0.9493\n",
      "Evaluation model on out of sample data...\n",
      "334/334 [==============================] - 6s 18ms/step - loss: 0.2728 - accuracy: 0.9170\n",
      "Calculating uncertainty scores...\n",
      "Most uncertain SHE2\n",
      "====================================================\n",
      "Active Learning Iteration #2\n",
      "Current Training Stations: ['AMD2', 'FLU2', 'SHE2']\n",
      "Epoch 1/10\n",
      "151/151 [==============================] - 4s 27ms/step - loss: 0.1321 - accuracy: 0.9518 - val_loss: 0.1540 - val_accuracy: 0.9399\n",
      "Epoch 2/10\n",
      "151/151 [==============================] - 4s 27ms/step - loss: 0.1284 - accuracy: 0.9511 - val_loss: 0.1419 - val_accuracy: 0.9458\n",
      "Epoch 3/10\n",
      "151/151 [==============================] - 4s 26ms/step - loss: 0.1239 - accuracy: 0.9532 - val_loss: 0.1490 - val_accuracy: 0.9458\n",
      "Epoch 4/10\n",
      "151/151 [==============================] - 4s 27ms/step - loss: 0.1251 - accuracy: 0.9539 - val_loss: 0.1437 - val_accuracy: 0.9474\n",
      "Epoch 5/10\n",
      "151/151 [==============================] - 4s 27ms/step - loss: 0.1236 - accuracy: 0.9543 - val_loss: 0.1507 - val_accuracy: 0.9428\n",
      "Epoch 6/10\n",
      "151/151 [==============================] - 4s 28ms/step - loss: 0.1190 - accuracy: 0.9554 - val_loss: 0.1567 - val_accuracy: 0.9449\n",
      "Epoch 7/10\n",
      "151/151 [==============================] - 4s 26ms/step - loss: 0.1186 - accuracy: 0.9561 - val_loss: 0.1556 - val_accuracy: 0.9445\n",
      "Epoch 8/10\n",
      "151/151 [==============================] - 4s 26ms/step - loss: 0.1162 - accuracy: 0.9566 - val_loss: 0.1597 - val_accuracy: 0.9441\n",
      "Epoch 9/10\n",
      "151/151 [==============================] - 4s 25ms/step - loss: 0.1169 - accuracy: 0.9558 - val_loss: 0.1442 - val_accuracy: 0.9464\n",
      "Epoch 10/10\n",
      "151/151 [==============================] - 4s 27ms/step - loss: 0.1148 - accuracy: 0.9559 - val_loss: 0.1672 - val_accuracy: 0.9441\n",
      "Evaluation model on out of sample data...\n",
      "334/334 [==============================] - 6s 19ms/step - loss: 0.2528 - accuracy: 0.9243\n",
      "Calculating uncertainty scores...\n",
      "Most uncertain GUT2\n",
      "====================================================\n",
      "Active Learning Iteration #3\n",
      "Current Training Stations: ['AMD2', 'FLU2', 'SHE2', 'GUT2']\n",
      "Epoch 1/10\n",
      "204/204 [==============================] - 6s 27ms/step - loss: 0.1227 - accuracy: 0.9551 - val_loss: 0.1494 - val_accuracy: 0.9490\n",
      "Epoch 2/10\n",
      "204/204 [==============================] - 5s 21ms/step - loss: 0.1167 - accuracy: 0.9574 - val_loss: 0.1571 - val_accuracy: 0.9458\n",
      "Epoch 3/10\n",
      "204/204 [==============================] - 5s 25ms/step - loss: 0.1147 - accuracy: 0.9581 - val_loss: 0.1486 - val_accuracy: 0.9481\n",
      "Epoch 4/10\n",
      "204/204 [==============================] - 6s 28ms/step - loss: 0.1135 - accuracy: 0.9584 - val_loss: 0.1485 - val_accuracy: 0.9489\n",
      "Epoch 5/10\n",
      "204/204 [==============================] - 6s 28ms/step - loss: 0.1118 - accuracy: 0.9594 - val_loss: 0.1494 - val_accuracy: 0.9510\n",
      "Epoch 6/10\n",
      "204/204 [==============================] - 6s 29ms/step - loss: 0.1111 - accuracy: 0.9594 - val_loss: 0.1475 - val_accuracy: 0.9476\n",
      "Epoch 7/10\n",
      "204/204 [==============================] - 6s 27ms/step - loss: 0.1092 - accuracy: 0.9605 - val_loss: 0.1502 - val_accuracy: 0.9509\n",
      "Epoch 8/10\n",
      "204/204 [==============================] - 6s 27ms/step - loss: 0.1079 - accuracy: 0.9615 - val_loss: 0.1551 - val_accuracy: 0.9480\n",
      "Epoch 9/10\n",
      "204/204 [==============================] - 6s 29ms/step - loss: 0.1055 - accuracy: 0.9619 - val_loss: 0.1522 - val_accuracy: 0.9483\n",
      "Epoch 10/10\n",
      "204/204 [==============================] - 6s 29ms/step - loss: 0.1095 - accuracy: 0.9606 - val_loss: 0.1577 - val_accuracy: 0.9501\n",
      "Evaluation model on out of sample data...\n",
      "334/334 [==============================] - 7s 19ms/step - loss: 0.2504 - accuracy: 0.9054\n",
      "Calculating uncertainty scores...\n",
      "Most uncertain ARO3\n",
      "====================================================\n",
      "Active Learning Iteration #4\n",
      "Current Training Stations: ['AMD2', 'FLU2', 'SHE2', 'GUT2', 'ARO3']\n",
      "Epoch 1/10\n",
      "264/264 [==============================] - 6s 23ms/step - loss: 0.1175 - accuracy: 0.9557 - val_loss: 0.1513 - val_accuracy: 0.9476\n",
      "Epoch 2/10\n",
      "264/264 [==============================] - 6s 21ms/step - loss: 0.1151 - accuracy: 0.9575 - val_loss: 0.1601 - val_accuracy: 0.9456\n",
      "Epoch 3/10\n",
      "264/264 [==============================] - 6s 21ms/step - loss: 0.1132 - accuracy: 0.9574 - val_loss: 0.1509 - val_accuracy: 0.9463\n",
      "Epoch 4/10\n",
      "264/264 [==============================] - 6s 21ms/step - loss: 0.1146 - accuracy: 0.9569 - val_loss: 0.1526 - val_accuracy: 0.9455\n",
      "Epoch 5/10\n",
      "264/264 [==============================] - 6s 21ms/step - loss: 0.1130 - accuracy: 0.9577 - val_loss: 0.1444 - val_accuracy: 0.9460\n",
      "Epoch 6/10\n",
      "264/264 [==============================] - 7s 25ms/step - loss: 0.1110 - accuracy: 0.9587 - val_loss: 0.1521 - val_accuracy: 0.9453\n",
      "Epoch 7/10\n",
      "264/264 [==============================] - 7s 27ms/step - loss: 0.1146 - accuracy: 0.9564 - val_loss: 0.1494 - val_accuracy: 0.9455\n",
      "Epoch 8/10\n",
      "264/264 [==============================] - 8s 28ms/step - loss: 0.1095 - accuracy: 0.9592 - val_loss: 0.1609 - val_accuracy: 0.9472\n",
      "Epoch 9/10\n",
      "264/264 [==============================] - 9s 32ms/step - loss: 0.1089 - accuracy: 0.9589 - val_loss: 0.1522 - val_accuracy: 0.9466\n",
      "Epoch 10/10\n",
      "264/264 [==============================] - 6s 23ms/step - loss: 0.1090 - accuracy: 0.9589 - val_loss: 0.1545 - val_accuracy: 0.9476\n",
      "Evaluation model on out of sample data...\n",
      "334/334 [==============================] - 6s 18ms/step - loss: 0.2599 - accuracy: 0.9141\n",
      "Calculating uncertainty scores...\n",
      "Most uncertain BOR2\n",
      "====================================================\n",
      "Active Learning Iteration #5\n",
      "Current Training Stations: ['AMD2', 'FLU2', 'SHE2', 'GUT2', 'ARO3', 'BOR2']\n",
      "Epoch 1/10\n",
      "313/313 [==============================] - 7s 22ms/step - loss: 0.1050 - accuracy: 0.9608 - val_loss: 0.1341 - val_accuracy: 0.9515\n",
      "Epoch 2/10\n",
      "313/313 [==============================] - 9s 27ms/step - loss: 0.1036 - accuracy: 0.9618 - val_loss: 0.1404 - val_accuracy: 0.9522\n",
      "Epoch 3/10\n",
      "313/313 [==============================] - 8s 26ms/step - loss: 0.1017 - accuracy: 0.9614 - val_loss: 0.1440 - val_accuracy: 0.9493\n",
      "Epoch 4/10\n",
      "313/313 [==============================] - 9s 29ms/step - loss: 0.1020 - accuracy: 0.9610 - val_loss: 0.1457 - val_accuracy: 0.9503\n",
      "Epoch 5/10\n",
      "313/313 [==============================] - 9s 27ms/step - loss: 0.1023 - accuracy: 0.9615 - val_loss: 0.1468 - val_accuracy: 0.9525\n",
      "Epoch 6/10\n",
      "313/313 [==============================] - 8s 26ms/step - loss: 0.1014 - accuracy: 0.9612 - val_loss: 0.1388 - val_accuracy: 0.9523\n",
      "Epoch 7/10\n",
      "313/313 [==============================] - 7s 22ms/step - loss: 0.0963 - accuracy: 0.9640 - val_loss: 0.1451 - val_accuracy: 0.9505\n",
      "Epoch 8/10\n",
      "313/313 [==============================] - 7s 22ms/step - loss: 0.0970 - accuracy: 0.9637 - val_loss: 0.1384 - val_accuracy: 0.9507\n",
      "Epoch 9/10\n",
      "313/313 [==============================] - 8s 26ms/step - loss: 0.0940 - accuracy: 0.9649 - val_loss: 0.1430 - val_accuracy: 0.9514\n",
      "Epoch 10/10\n",
      "313/313 [==============================] - 8s 26ms/step - loss: 0.0945 - accuracy: 0.9641 - val_loss: 0.1493 - val_accuracy: 0.9511\n",
      "Evaluation model on out of sample data...\n",
      "334/334 [==============================] - 7s 19ms/step - loss: 0.2418 - accuracy: 0.9254\n",
      "Calculating uncertainty scores...\n",
      "Most uncertain TUM2\n",
      "====================================================\n",
      "Active Learning Iteration #6\n",
      "Current Training Stations: ['AMD2', 'FLU2', 'SHE2', 'GUT2', 'ARO3', 'BOR2', 'TUM2']\n",
      "Epoch 1/10\n",
      "359/359 [==============================] - 10s 26ms/step - loss: 0.0945 - accuracy: 0.9654 - val_loss: 0.1433 - val_accuracy: 0.9504\n",
      "Epoch 2/10\n",
      "359/359 [==============================] - 10s 26ms/step - loss: 0.0900 - accuracy: 0.9671 - val_loss: 0.1322 - val_accuracy: 0.9533\n",
      "Epoch 3/10\n",
      "359/359 [==============================] - 11s 29ms/step - loss: 0.0889 - accuracy: 0.9672 - val_loss: 0.1348 - val_accuracy: 0.9537\n",
      "Epoch 4/10\n",
      "359/359 [==============================] - 9s 24ms/step - loss: 0.0888 - accuracy: 0.9674 - val_loss: 0.1369 - val_accuracy: 0.9520\n",
      "Epoch 5/10\n",
      "359/359 [==============================] - 9s 24ms/step - loss: 0.0882 - accuracy: 0.9670 - val_loss: 0.1321 - val_accuracy: 0.9531\n",
      "Epoch 6/10\n",
      "359/359 [==============================] - 10s 27ms/step - loss: 0.0859 - accuracy: 0.9684 - val_loss: 0.1409 - val_accuracy: 0.9517\n",
      "Epoch 7/10\n",
      "359/359 [==============================] - 11s 29ms/step - loss: 0.0844 - accuracy: 0.9689 - val_loss: 0.1338 - val_accuracy: 0.9537\n",
      "Epoch 8/10\n",
      "359/359 [==============================] - 9s 24ms/step - loss: 0.0843 - accuracy: 0.9684 - val_loss: 0.1417 - val_accuracy: 0.9545\n",
      "Epoch 9/10\n",
      "359/359 [==============================] - 8s 23ms/step - loss: 0.0828 - accuracy: 0.9691 - val_loss: 0.1370 - val_accuracy: 0.9531\n",
      "Epoch 10/10\n",
      "359/359 [==============================] - 10s 27ms/step - loss: 0.0850 - accuracy: 0.9686 - val_loss: 0.1325 - val_accuracy: 0.9532\n",
      "Evaluation model on out of sample data...\n",
      "334/334 [==============================] - 7s 19ms/step - loss: 0.2499 - accuracy: 0.9281\n",
      "Calculating uncertainty scores...\n",
      "Most uncertain SPN2\n",
      "====================================================\n",
      "Active Learning Iteration #7\n",
      "Current Training Stations: ['AMD2', 'FLU2', 'SHE2', 'GUT2', 'ARO3', 'BOR2', 'TUM2', 'SPN2']\n",
      "Epoch 1/10\n",
      "419/419 [==============================] - 12s 29ms/step - loss: 0.1188 - accuracy: 0.9568 - val_loss: 0.1405 - val_accuracy: 0.9486\n",
      "Epoch 2/10\n",
      "419/419 [==============================] - 12s 27ms/step - loss: 0.1103 - accuracy: 0.9586 - val_loss: 0.1369 - val_accuracy: 0.9483\n",
      "Epoch 3/10\n",
      "419/419 [==============================] - 12s 28ms/step - loss: 0.1064 - accuracy: 0.9601 - val_loss: 0.1386 - val_accuracy: 0.9471\n",
      "Epoch 4/10\n",
      "419/419 [==============================] - 9s 21ms/step - loss: 0.1067 - accuracy: 0.9597 - val_loss: 0.1429 - val_accuracy: 0.9478\n",
      "Epoch 5/10\n",
      "419/419 [==============================] - 11s 25ms/step - loss: 0.1039 - accuracy: 0.9619 - val_loss: 0.1548 - val_accuracy: 0.9450\n",
      "Epoch 6/10\n",
      "419/419 [==============================] - 11s 26ms/step - loss: 0.1019 - accuracy: 0.9623 - val_loss: 0.1530 - val_accuracy: 0.9429\n",
      "Epoch 7/10\n",
      "419/419 [==============================] - 11s 27ms/step - loss: 0.0994 - accuracy: 0.9632 - val_loss: 0.1542 - val_accuracy: 0.9440\n",
      "Epoch 8/10\n",
      "419/419 [==============================] - 11s 26ms/step - loss: 0.0964 - accuracy: 0.9648 - val_loss: 0.1477 - val_accuracy: 0.9493\n",
      "Epoch 9/10\n",
      "419/419 [==============================] - 11s 26ms/step - loss: 0.0970 - accuracy: 0.9650 - val_loss: 0.1496 - val_accuracy: 0.9455\n",
      "Epoch 10/10\n",
      "419/419 [==============================] - 11s 27ms/step - loss: 0.0952 - accuracy: 0.9651 - val_loss: 0.1558 - val_accuracy: 0.9470\n",
      "Evaluation model on out of sample data...\n",
      "334/334 [==============================] - 6s 18ms/step - loss: 0.2729 - accuracy: 0.9276\n",
      "Calculating uncertainty scores...\n",
      "Most uncertain FNH2\n",
      "====================================================\n",
      "Active Learning Iteration #8\n",
      "Current Training Stations: ['AMD2', 'FLU2', 'SHE2', 'GUT2', 'ARO3', 'BOR2', 'TUM2', 'SPN2', 'FNH2']\n",
      "Epoch 1/10\n",
      "477/477 [==============================] - 11s 22ms/step - loss: 0.0943 - accuracy: 0.9656 - val_loss: 0.1400 - val_accuracy: 0.9484\n",
      "Epoch 2/10\n",
      "477/477 [==============================] - 10s 21ms/step - loss: 0.0917 - accuracy: 0.9664 - val_loss: 0.1440 - val_accuracy: 0.9494\n",
      "Epoch 3/10\n",
      "477/477 [==============================] - 13s 27ms/step - loss: 0.0887 - accuracy: 0.9675 - val_loss: 0.1507 - val_accuracy: 0.9484\n",
      "Epoch 4/10\n",
      "477/477 [==============================] - 13s 28ms/step - loss: 0.0894 - accuracy: 0.9671 - val_loss: 0.1411 - val_accuracy: 0.9485\n",
      "Epoch 5/10\n",
      "477/477 [==============================] - 13s 27ms/step - loss: 0.0862 - accuracy: 0.9678 - val_loss: 0.1406 - val_accuracy: 0.9501\n",
      "Epoch 6/10\n",
      "477/477 [==============================] - 13s 27ms/step - loss: 0.0831 - accuracy: 0.9692 - val_loss: 0.1478 - val_accuracy: 0.9482\n",
      "Epoch 7/10\n",
      "477/477 [==============================] - 13s 27ms/step - loss: 0.0835 - accuracy: 0.9690 - val_loss: 0.1533 - val_accuracy: 0.9478\n",
      "Epoch 8/10\n",
      "477/477 [==============================] - 13s 27ms/step - loss: 0.0828 - accuracy: 0.9688 - val_loss: 0.1503 - val_accuracy: 0.9484\n",
      "Epoch 9/10\n",
      "477/477 [==============================] - 13s 27ms/step - loss: 0.0810 - accuracy: 0.9697 - val_loss: 0.1502 - val_accuracy: 0.9471\n",
      "Epoch 10/10\n",
      "477/477 [==============================] - 13s 26ms/step - loss: 0.0776 - accuracy: 0.9708 - val_loss: 0.1538 - val_accuracy: 0.9487\n",
      "Evaluation model on out of sample data...\n",
      "334/334 [==============================] - 6s 19ms/step - loss: 0.2738 - accuracy: 0.9304\n",
      "Calculating uncertainty scores...\n",
      "Most uncertain SLF2\n",
      "====================================================\n",
      "Active Learning Iteration #9\n",
      "Current Training Stations: ['AMD2', 'FLU2', 'SHE2', 'GUT2', 'ARO3', 'BOR2', 'TUM2', 'SPN2', 'FNH2', 'SLF2']\n",
      "Epoch 1/10\n",
      "535/535 [==============================] - 12s 21ms/step - loss: 0.0975 - accuracy: 0.9646 - val_loss: 0.1396 - val_accuracy: 0.9492\n",
      "Epoch 2/10\n",
      "535/535 [==============================] - 14s 27ms/step - loss: 0.0880 - accuracy: 0.9675 - val_loss: 0.1327 - val_accuracy: 0.9518\n",
      "Epoch 3/10\n",
      "535/535 [==============================] - 14s 26ms/step - loss: 0.0821 - accuracy: 0.9693 - val_loss: 0.1365 - val_accuracy: 0.9495\n",
      "Epoch 4/10\n",
      "535/535 [==============================] - 14s 26ms/step - loss: 0.0808 - accuracy: 0.9696 - val_loss: 0.1297 - val_accuracy: 0.9522\n",
      "Epoch 5/10\n",
      "535/535 [==============================] - 14s 26ms/step - loss: 0.0812 - accuracy: 0.9696 - val_loss: 0.1339 - val_accuracy: 0.9523\n",
      "Epoch 6/10\n",
      "535/535 [==============================] - 12s 22ms/step - loss: 0.0746 - accuracy: 0.9725 - val_loss: 0.1366 - val_accuracy: 0.9523\n",
      "Epoch 7/10\n",
      "535/535 [==============================] - 14s 27ms/step - loss: 0.0746 - accuracy: 0.9727 - val_loss: 0.1408 - val_accuracy: 0.9497\n",
      "Epoch 8/10\n",
      "535/535 [==============================] - 14s 26ms/step - loss: 0.0741 - accuracy: 0.9723 - val_loss: 0.1420 - val_accuracy: 0.9503\n",
      "Epoch 9/10\n",
      "535/535 [==============================] - 14s 25ms/step - loss: 0.0715 - accuracy: 0.9733 - val_loss: 0.1422 - val_accuracy: 0.9513\n",
      "Epoch 10/10\n",
      "535/535 [==============================] - 15s 27ms/step - loss: 0.0714 - accuracy: 0.9731 - val_loss: 0.1411 - val_accuracy: 0.9508\n",
      "Evaluation model on out of sample data...\n",
      "334/334 [==============================] - 6s 18ms/step - loss: 0.3208 - accuracy: 0.9255\n",
      "Calculating uncertainty scores...\n",
      "Most uncertain LAG3\n",
      "====================================================\n",
      "Active Learning Iteration #10\n",
      "Current Training Stations: ['AMD2', 'FLU2', 'SHE2', 'GUT2', 'ARO3', 'BOR2', 'TUM2', 'SPN2', 'FNH2', 'SLF2', 'LAG3']\n",
      "Epoch 1/10\n",
      "565/565 [==============================] - 16s 28ms/step - loss: 0.0733 - accuracy: 0.9740 - val_loss: 0.1377 - val_accuracy: 0.9513\n",
      "Epoch 2/10\n",
      "565/565 [==============================] - 16s 27ms/step - loss: 0.0747 - accuracy: 0.9732 - val_loss: 0.1400 - val_accuracy: 0.9477\n",
      "Epoch 3/10\n",
      "565/565 [==============================] - 16s 28ms/step - loss: 0.0722 - accuracy: 0.9739 - val_loss: 0.1417 - val_accuracy: 0.9506\n",
      "Epoch 4/10\n",
      "565/565 [==============================] - 16s 28ms/step - loss: 0.0692 - accuracy: 0.9747 - val_loss: 0.1450 - val_accuracy: 0.9499\n",
      "Epoch 5/10\n",
      "565/565 [==============================] - 16s 28ms/step - loss: 0.0686 - accuracy: 0.9752 - val_loss: 0.1447 - val_accuracy: 0.9493\n",
      "Epoch 6/10\n",
      "565/565 [==============================] - 15s 26ms/step - loss: 0.0686 - accuracy: 0.9758 - val_loss: 0.1444 - val_accuracy: 0.9520\n",
      "Epoch 7/10\n",
      "565/565 [==============================] - 15s 27ms/step - loss: 0.0705 - accuracy: 0.9749 - val_loss: 0.1434 - val_accuracy: 0.9503\n",
      "Epoch 8/10\n",
      "565/565 [==============================] - 14s 24ms/step - loss: 0.0662 - accuracy: 0.9763 - val_loss: 0.1487 - val_accuracy: 0.9515\n",
      "Epoch 9/10\n",
      "565/565 [==============================] - 15s 26ms/step - loss: 0.0640 - accuracy: 0.9772 - val_loss: 0.1509 - val_accuracy: 0.9506\n",
      "Epoch 10/10\n",
      "565/565 [==============================] - 15s 27ms/step - loss: 0.0701 - accuracy: 0.9742 - val_loss: 0.1471 - val_accuracy: 0.9477\n",
      "Evaluation model on out of sample data...\n",
      "334/334 [==============================] - 6s 19ms/step - loss: 0.3160 - accuracy: 0.9264\n",
      "Calculating uncertainty scores...\n",
      "Most uncertain STN2\n",
      "====================================================\n",
      "Active Learning Iteration #11\n",
      "Current Training Stations: ['AMD2', 'FLU2', 'SHE2', 'GUT2', 'ARO3', 'BOR2', 'TUM2', 'SPN2', 'FNH2', 'SLF2', 'LAG3', 'STN2']\n",
      "Epoch 1/10\n",
      "621/621 [==============================] - 15s 24ms/step - loss: 0.0751 - accuracy: 0.9733 - val_loss: 0.1427 - val_accuracy: 0.9484\n",
      "Epoch 2/10\n",
      "621/621 [==============================] - 17s 26ms/step - loss: 0.0685 - accuracy: 0.9752 - val_loss: 0.1440 - val_accuracy: 0.9482\n",
      "Epoch 3/10\n",
      "621/621 [==============================] - 17s 27ms/step - loss: 0.0689 - accuracy: 0.9750 - val_loss: 0.1548 - val_accuracy: 0.9483\n",
      "Epoch 4/10\n",
      "621/621 [==============================] - 17s 27ms/step - loss: 0.0665 - accuracy: 0.9762 - val_loss: 0.1479 - val_accuracy: 0.9512\n",
      "Epoch 5/10\n",
      "621/621 [==============================] - 17s 27ms/step - loss: 0.0749 - accuracy: 0.9725 - val_loss: 0.1307 - val_accuracy: 0.9523\n",
      "Epoch 6/10\n",
      "621/621 [==============================] - 15s 23ms/step - loss: 0.0718 - accuracy: 0.9740 - val_loss: 0.1479 - val_accuracy: 0.9464\n",
      "Epoch 7/10\n",
      "621/621 [==============================] - 15s 24ms/step - loss: 0.0669 - accuracy: 0.9763 - val_loss: 0.1442 - val_accuracy: 0.9495\n",
      "Epoch 8/10\n",
      "621/621 [==============================] - 16s 26ms/step - loss: 0.0659 - accuracy: 0.9759 - val_loss: 0.1476 - val_accuracy: 0.9495\n",
      "Epoch 9/10\n",
      "621/621 [==============================] - 18s 28ms/step - loss: 0.0645 - accuracy: 0.9771 - val_loss: 0.1493 - val_accuracy: 0.9499\n",
      "Epoch 10/10\n",
      "621/621 [==============================] - 18s 29ms/step - loss: 0.0618 - accuracy: 0.9776 - val_loss: 0.1425 - val_accuracy: 0.9505\n",
      "Evaluation model on out of sample data...\n",
      "334/334 [==============================] - 7s 20ms/step - loss: 0.2712 - accuracy: 0.9332\n",
      "Calculating uncertainty scores...\n",
      "Most uncertain KLO2\n",
      "====================================================\n",
      "Active Learning Iteration #12\n",
      "Current Training Stations: ['AMD2', 'FLU2', 'SHE2', 'GUT2', 'ARO3', 'BOR2', 'TUM2', 'SPN2', 'FNH2', 'SLF2', 'LAG3', 'STN2', 'KLO2']\n",
      "Epoch 1/10\n",
      "681/681 [==============================] - 18s 26ms/step - loss: 0.0658 - accuracy: 0.9766 - val_loss: 0.1342 - val_accuracy: 0.9554\n",
      "Epoch 2/10\n",
      "681/681 [==============================] - 18s 26ms/step - loss: 0.0643 - accuracy: 0.9768 - val_loss: 0.1378 - val_accuracy: 0.9533\n",
      "Epoch 3/10\n",
      "681/681 [==============================] - 16s 23ms/step - loss: 0.0663 - accuracy: 0.9759 - val_loss: 0.1421 - val_accuracy: 0.9501\n",
      "Epoch 4/10\n",
      "681/681 [==============================] - 18s 26ms/step - loss: 0.0624 - accuracy: 0.9774 - val_loss: 0.1470 - val_accuracy: 0.9503\n",
      "Epoch 5/10\n",
      "681/681 [==============================] - 18s 26ms/step - loss: 0.0640 - accuracy: 0.9763 - val_loss: 0.1403 - val_accuracy: 0.9536\n",
      "Epoch 6/10\n",
      "681/681 [==============================] - 18s 26ms/step - loss: 0.0614 - accuracy: 0.9778 - val_loss: 0.1393 - val_accuracy: 0.9528\n",
      "Epoch 7/10\n",
      "681/681 [==============================] - 18s 26ms/step - loss: 0.0615 - accuracy: 0.9775 - val_loss: 0.1471 - val_accuracy: 0.9494\n",
      "Epoch 8/10\n",
      "681/681 [==============================] - 18s 26ms/step - loss: 0.0607 - accuracy: 0.9783 - val_loss: 0.1390 - val_accuracy: 0.9526\n",
      "Epoch 9/10\n",
      "681/681 [==============================] - 17s 25ms/step - loss: 0.0589 - accuracy: 0.9785 - val_loss: 0.1508 - val_accuracy: 0.9522\n",
      "Epoch 10/10\n",
      "681/681 [==============================] - 17s 25ms/step - loss: 0.0585 - accuracy: 0.9788 - val_loss: 0.1591 - val_accuracy: 0.9475\n",
      "Evaluation model on out of sample data...\n",
      "334/334 [==============================] - 6s 17ms/step - loss: 0.2791 - accuracy: 0.9314\n",
      "Calculating uncertainty scores...\n",
      "Most uncertain GLA2\n",
      "====================================================\n",
      "Active Learning Iteration #13\n",
      "Current Training Stations: ['AMD2', 'FLU2', 'SHE2', 'GUT2', 'ARO3', 'BOR2', 'TUM2', 'SPN2', 'FNH2', 'SLF2', 'LAG3', 'STN2', 'KLO2', 'GLA2']\n",
      "Epoch 1/10\n",
      "731/731 [==============================] - 19s 26ms/step - loss: 0.0658 - accuracy: 0.9767 - val_loss: 0.1473 - val_accuracy: 0.9489\n",
      "Epoch 2/10\n",
      "731/731 [==============================] - 17s 23ms/step - loss: 0.0603 - accuracy: 0.9784 - val_loss: 0.1629 - val_accuracy: 0.9473\n",
      "Epoch 3/10\n",
      "731/731 [==============================] - 20s 27ms/step - loss: 0.0602 - accuracy: 0.9779 - val_loss: 0.1583 - val_accuracy: 0.9489\n",
      "Epoch 4/10\n",
      "731/731 [==============================] - 21s 28ms/step - loss: 0.0589 - accuracy: 0.9783 - val_loss: 0.1487 - val_accuracy: 0.9501\n",
      "Epoch 5/10\n",
      "731/731 [==============================] - 20s 27ms/step - loss: 0.0571 - accuracy: 0.9795 - val_loss: 0.1574 - val_accuracy: 0.9501\n",
      "Epoch 6/10\n",
      "731/731 [==============================] - 20s 27ms/step - loss: 0.0567 - accuracy: 0.9797 - val_loss: 0.1580 - val_accuracy: 0.9499\n",
      "Epoch 7/10\n",
      "731/731 [==============================] - 17s 24ms/step - loss: 0.0562 - accuracy: 0.9797 - val_loss: 0.1712 - val_accuracy: 0.9453\n",
      "Epoch 8/10\n",
      "731/731 [==============================] - 19s 26ms/step - loss: 0.0554 - accuracy: 0.9797 - val_loss: 0.1582 - val_accuracy: 0.9526\n",
      "Epoch 9/10\n",
      "731/731 [==============================] - 19s 26ms/step - loss: 0.0556 - accuracy: 0.9799 - val_loss: 0.1584 - val_accuracy: 0.9510\n",
      "Epoch 10/10\n",
      "731/731 [==============================] - 16s 22ms/step - loss: 0.0556 - accuracy: 0.9801 - val_loss: 0.1585 - val_accuracy: 0.9501\n",
      "Evaluation model on out of sample data...\n",
      "334/334 [==============================] - 6s 17ms/step - loss: 0.2791 - accuracy: 0.9355\n",
      "Calculating uncertainty scores...\n",
      "Most uncertain TRU2\n",
      "====================================================\n",
      "Active Learning Iteration #14\n",
      "Current Training Stations: ['AMD2', 'FLU2', 'SHE2', 'GUT2', 'ARO3', 'BOR2', 'TUM2', 'SPN2', 'FNH2', 'SLF2', 'LAG3', 'STN2', 'KLO2', 'GLA2', 'TRU2']\n",
      "Epoch 1/10\n",
      "791/791 [==============================] - 21s 26ms/step - loss: 0.0607 - accuracy: 0.9782 - val_loss: 0.1456 - val_accuracy: 0.9522\n",
      "Epoch 2/10\n",
      "791/791 [==============================] - 21s 27ms/step - loss: 0.0582 - accuracy: 0.9789 - val_loss: 0.1454 - val_accuracy: 0.9533\n",
      "Epoch 3/10\n",
      "791/791 [==============================] - 21s 27ms/step - loss: 0.0567 - accuracy: 0.9792 - val_loss: 0.1426 - val_accuracy: 0.9532\n",
      "Epoch 4/10\n",
      "791/791 [==============================] - 21s 26ms/step - loss: 0.0568 - accuracy: 0.9789 - val_loss: 0.1576 - val_accuracy: 0.9474\n",
      "Epoch 5/10\n",
      "791/791 [==============================] - 23s 29ms/step - loss: 0.0553 - accuracy: 0.9796 - val_loss: 0.1474 - val_accuracy: 0.9514\n",
      "Epoch 6/10\n",
      "791/791 [==============================] - 19s 24ms/step - loss: 0.0555 - accuracy: 0.9794 - val_loss: 0.1509 - val_accuracy: 0.9501\n",
      "Epoch 7/10\n",
      "791/791 [==============================] - 22s 28ms/step - loss: 0.0547 - accuracy: 0.9795 - val_loss: 0.1507 - val_accuracy: 0.9504\n",
      "Epoch 8/10\n",
      "791/791 [==============================] - 21s 26ms/step - loss: 0.0533 - accuracy: 0.9808 - val_loss: 0.1617 - val_accuracy: 0.9521\n",
      "Epoch 9/10\n",
      "791/791 [==============================] - 21s 27ms/step - loss: 0.0541 - accuracy: 0.9800 - val_loss: 0.1555 - val_accuracy: 0.9509\n",
      "Epoch 10/10\n",
      "791/791 [==============================] - 21s 27ms/step - loss: 0.0515 - accuracy: 0.9808 - val_loss: 0.1536 - val_accuracy: 0.9510\n",
      "Evaluation model on out of sample data...\n",
      "334/334 [==============================] - 7s 20ms/step - loss: 0.2815 - accuracy: 0.9364\n"
     ]
    }
   ],
   "source": [
    "# arch = \"128(l)-64-8(d)-15\n",
    "arch = \"128(l)-64-8(d)-1\"\n",
    "sequence_length = 30 # TODO: Make sequence length global\n",
    "input_shape = (sequence_length, 5) # TODO: Replace with variable that contains number of features\n",
    "epochs = 10\n",
    "model_batch_size = 64\n",
    "\n",
    "network = create_network(arch, input_shape)\n",
    "\n",
    "model = keras.Sequential(network)\n",
    "model.compile(\n",
    "    optimizer='adam',\n",
    "    metrics='accuracy',\n",
    "    loss='binary_crossentropy'\n",
    ")\n",
    "\n",
    "group_split_num = 15\n",
    "last_training_station = df['station_code'].unique()[:group_split_num]\n",
    "active_learning_samples_index = df[df['station_code'] == last_training_station[-1]].index[-1] + 1\n",
    "\n",
    "active_learning_df = df[:active_learning_samples_index]\n",
    "out_of_sample_df = df[active_learning_samples_index:]\n",
    "\n",
    "active_stations = np.random.choice(active_learning_df['station_code'].unique(), 1).tolist()\n",
    "split_percentage = 0.8\n",
    "summary = []\n",
    "\n",
    "for i in range(group_split_num):\n",
    "    print(f'====================================================')\n",
    "    print(f'Active Learning Iteration #{i}')\n",
    "    print(f'Current Training Stations: {active_stations}')\n",
    "    current_iteration_train_df, current_iteration_val_df = pd.DataFrame(), pd.DataFrame()\n",
    "\n",
    "    for station in active_stations:\n",
    "        station_data = df[df['station_code'] == station]\n",
    "        split_index = int(len(station_data) * split_percentage)\n",
    "\n",
    "        current_iteration_train_df = pd.concat([current_iteration_train_df, station_data[:split_index]])\n",
    "        current_iteration_val_df = pd.concat([current_iteration_val_df, station_data[split_index:]])\n",
    "\n",
    "    current_iteration_df = pd.concat([current_iteration_train_df, current_iteration_val_df])\n",
    "    split_index = len(current_iteration_train_df)\n",
    "    \n",
    "    print(f'Training samples: {len(current_iteration_train_df)}')\n",
    "    print(f'Validation samples: {len(current_iteration_val_df)}')\n",
    "    \n",
    "    current_iteration_features, current_iteration_targets, current_iteration_mean, current_iteration_std = get_features_and_targets(current_iteration_df, split_index)\n",
    "    \n",
    "    current_iteration_train_dataset = create_dataset(current_iteration_features, current_iteration_targets, end_index=split_index, shuffle=True)\n",
    "    current_iteration_val_dataset = create_dataset(current_iteration_features, current_iteration_targets, start_index=split_index, shuffle=True)\n",
    "    \n",
    "    history = model.fit(current_iteration_train_dataset, epochs=epochs, batch_size=model_batch_size, validation_data=current_iteration_val_dataset)\n",
    "\n",
    "    out_of_sample_features, out_of_sample_targets, _, _ = get_features_and_targets(out_of_sample_df, mean=current_iteration_mean, std=current_iteration_std)\n",
    "    out_of_sample_dataset = create_dataset(out_of_sample_features, out_of_sample_targets, shuffle=True)\n",
    "\n",
    "    print(f'Evaluation model on out of sample data...')\n",
    "    evaluation_results = model.evaluate(out_of_sample_dataset)\n",
    "\n",
    "    inactive_stations_grouped = active_learning_df[~active_learning_df['station_code'].isin(active_stations)].groupby('station_code')\n",
    "    uncertainties = {}\n",
    "    most_uncertain_station_name = None\n",
    "    \n",
    "    if inactive_stations_grouped.ngroups != 0:\n",
    "        print(f'Calculating uncertainty scores...')\n",
    "        for name, group in inactive_stations_grouped:\n",
    "            inactive_station_df = group.reset_index(drop=True)\n",
    "            inactive_station_features, inactive_station_targets, _, _ = get_features_and_targets(inactive_station_df, scale=False)\n",
    "            inactive_station_dataset = create_dataset(inactive_station_features, inactive_station_targets, shuffle=True)\n",
    "            uncertainty_score = predict_with_uncertainty(model, inactive_station_dataset, n_iter=5)\n",
    "            uncertainties[name] = uncertainty_score\n",
    "\n",
    "        most_uncertain_station_name = max(uncertainties, key=uncertainties.get)\n",
    "\n",
    "        print(f'Most uncertain {most_uncertain_station_name}')\n",
    "\n",
    "    summary.append({\n",
    "        'iteration': i,\n",
    "        'active_learning_train': active_stations.copy(),\n",
    "        'active_learning_predict': uncertainties.keys(),\n",
    "        'evaluation_results': evaluation_results,\n",
    "        'uncertainty_scores': uncertainties,\n",
    "        'most_uncertain': most_uncertain_station_name\n",
    "    })\n",
    "\n",
    "    active_stations.append(most_uncertain_station_name)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-02T11:13:14.444353137Z",
     "start_time": "2023-11-02T10:30:07.039295792Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [
    {
     "data": {
      "text/plain": "    iteration                              active_learning_train  \\\n0           0                                             [AMD2]   \n1           1                                       [AMD2, FLU2]   \n2           2                                 [AMD2, FLU2, SHE2]   \n3           3                           [AMD2, FLU2, SHE2, GUT2]   \n4           4                     [AMD2, FLU2, SHE2, GUT2, ARO3]   \n5           5               [AMD2, FLU2, SHE2, GUT2, ARO3, BOR2]   \n6           6         [AMD2, FLU2, SHE2, GUT2, ARO3, BOR2, TUM2]   \n7           7   [AMD2, FLU2, SHE2, GUT2, ARO3, BOR2, TUM2, SPN2]   \n8           8  [AMD2, FLU2, SHE2, GUT2, ARO3, BOR2, TUM2, SPN...   \n9           9  [AMD2, FLU2, SHE2, GUT2, ARO3, BOR2, TUM2, SPN...   \n10         10  [AMD2, FLU2, SHE2, GUT2, ARO3, BOR2, TUM2, SPN...   \n11         11  [AMD2, FLU2, SHE2, GUT2, ARO3, BOR2, TUM2, SPN...   \n12         12  [AMD2, FLU2, SHE2, GUT2, ARO3, BOR2, TUM2, SPN...   \n13         13  [AMD2, FLU2, SHE2, GUT2, ARO3, BOR2, TUM2, SPN...   \n14         14  [AMD2, FLU2, SHE2, GUT2, ARO3, BOR2, TUM2, SPN...   \n\n                              active_learning_predict  \\\n0   (ARO3, BOR2, FLU2, FNH2, GLA2, GUT2, KLO2, LAG...   \n1   (ARO3, BOR2, FNH2, GLA2, GUT2, KLO2, LAG3, SHE...   \n2   (ARO3, BOR2, FNH2, GLA2, GUT2, KLO2, LAG3, SLF...   \n3   (ARO3, BOR2, FNH2, GLA2, KLO2, LAG3, SLF2, SPN...   \n4   (BOR2, FNH2, GLA2, KLO2, LAG3, SLF2, SPN2, STN...   \n5   (FNH2, GLA2, KLO2, LAG3, SLF2, SPN2, STN2, TRU...   \n6    (FNH2, GLA2, KLO2, LAG3, SLF2, SPN2, STN2, TRU2)   \n7          (FNH2, GLA2, KLO2, LAG3, SLF2, STN2, TRU2)   \n8                (GLA2, KLO2, LAG3, SLF2, STN2, TRU2)   \n9                      (GLA2, KLO2, LAG3, STN2, TRU2)   \n10                           (GLA2, KLO2, STN2, TRU2)   \n11                                 (GLA2, KLO2, TRU2)   \n12                                       (GLA2, TRU2)   \n13                                             (TRU2)   \n14                                                 ()   \n\n                           evaluation_results  \\\n0   [0.28082573413848877, 0.9121488928794861]   \n1   [0.27283939719200134, 0.9169943928718567]   \n2   [0.25275057554244995, 0.9242509603500366]   \n3    [0.2503879964351654, 0.9054073095321655]   \n4    [0.25987204909324646, 0.914068341255188]   \n5   [0.24178752303123474, 0.9254213571548462]   \n6   [0.24985019862651825, 0.9280664920806885]   \n7    [0.2729203701019287, 0.9275749325752258]   \n8    [0.2737712562084198, 0.9303604960441589]   \n9    [0.3208243250846863, 0.9254915714263916]   \n10  [0.31596946716308594, 0.9263811111450195]   \n11  [0.27117809653282166, 0.9332162737846375]   \n12   [0.2791396677494049, 0.9313904643058777]   \n13   [0.27906256914138794, 0.935486912727356]   \n14   [0.2815271019935608, 0.9363998174667358]   \n\n                                   uncertainty_scores most_uncertain  \n0   {'ARO3': 0.11018798, 'BOR2': 0.004916646, 'FLU...           FLU2  \n1   {'ARO3': 0.3407839, 'BOR2': 0.30149218, 'FNH2'...           SHE2  \n2   {'ARO3': 0.41040796, 'BOR2': 0.4169323, 'FNH2'...           GUT2  \n3   {'ARO3': 0.5501397, 'BOR2': 0.46590984, 'FNH2'...           ARO3  \n4   {'BOR2': 0.5974509, 'FNH2': 0.39873096, 'GLA2'...           BOR2  \n5   {'FNH2': 0.4364455, 'GLA2': 0.44914964, 'KLO2'...           TUM2  \n6   {'FNH2': 0.43804374, 'GLA2': 0.44044307, 'KLO2...           SPN2  \n7   {'FNH2': 0.56565034, 'GLA2': 0.51399, 'KLO2': ...           FNH2  \n8   {'GLA2': 0.4401654, 'KLO2': 0.44279513, 'LAG3'...           SLF2  \n9   {'GLA2': 0.43723786, 'KLO2': 0.4470492, 'LAG3'...           LAG3  \n10  {'GLA2': 0.36698827, 'KLO2': 0.4165741, 'STN2'...           STN2  \n11  {'GLA2': 0.30344704, 'KLO2': 0.36707085, 'TRU2...           KLO2  \n12              {'GLA2': 0.26802, 'TRU2': 0.24032019}           GLA2  \n13                               {'TRU2': 0.29970127}           TRU2  \n14                                                 {}           None  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>iteration</th>\n      <th>active_learning_train</th>\n      <th>active_learning_predict</th>\n      <th>evaluation_results</th>\n      <th>uncertainty_scores</th>\n      <th>most_uncertain</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>[AMD2]</td>\n      <td>(ARO3, BOR2, FLU2, FNH2, GLA2, GUT2, KLO2, LAG...</td>\n      <td>[0.28082573413848877, 0.9121488928794861]</td>\n      <td>{'ARO3': 0.11018798, 'BOR2': 0.004916646, 'FLU...</td>\n      <td>FLU2</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>[AMD2, FLU2]</td>\n      <td>(ARO3, BOR2, FNH2, GLA2, GUT2, KLO2, LAG3, SHE...</td>\n      <td>[0.27283939719200134, 0.9169943928718567]</td>\n      <td>{'ARO3': 0.3407839, 'BOR2': 0.30149218, 'FNH2'...</td>\n      <td>SHE2</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2</td>\n      <td>[AMD2, FLU2, SHE2]</td>\n      <td>(ARO3, BOR2, FNH2, GLA2, GUT2, KLO2, LAG3, SLF...</td>\n      <td>[0.25275057554244995, 0.9242509603500366]</td>\n      <td>{'ARO3': 0.41040796, 'BOR2': 0.4169323, 'FNH2'...</td>\n      <td>GUT2</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>3</td>\n      <td>[AMD2, FLU2, SHE2, GUT2]</td>\n      <td>(ARO3, BOR2, FNH2, GLA2, KLO2, LAG3, SLF2, SPN...</td>\n      <td>[0.2503879964351654, 0.9054073095321655]</td>\n      <td>{'ARO3': 0.5501397, 'BOR2': 0.46590984, 'FNH2'...</td>\n      <td>ARO3</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>4</td>\n      <td>[AMD2, FLU2, SHE2, GUT2, ARO3]</td>\n      <td>(BOR2, FNH2, GLA2, KLO2, LAG3, SLF2, SPN2, STN...</td>\n      <td>[0.25987204909324646, 0.914068341255188]</td>\n      <td>{'BOR2': 0.5974509, 'FNH2': 0.39873096, 'GLA2'...</td>\n      <td>BOR2</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>5</td>\n      <td>[AMD2, FLU2, SHE2, GUT2, ARO3, BOR2]</td>\n      <td>(FNH2, GLA2, KLO2, LAG3, SLF2, SPN2, STN2, TRU...</td>\n      <td>[0.24178752303123474, 0.9254213571548462]</td>\n      <td>{'FNH2': 0.4364455, 'GLA2': 0.44914964, 'KLO2'...</td>\n      <td>TUM2</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>6</td>\n      <td>[AMD2, FLU2, SHE2, GUT2, ARO3, BOR2, TUM2]</td>\n      <td>(FNH2, GLA2, KLO2, LAG3, SLF2, SPN2, STN2, TRU2)</td>\n      <td>[0.24985019862651825, 0.9280664920806885]</td>\n      <td>{'FNH2': 0.43804374, 'GLA2': 0.44044307, 'KLO2...</td>\n      <td>SPN2</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>7</td>\n      <td>[AMD2, FLU2, SHE2, GUT2, ARO3, BOR2, TUM2, SPN2]</td>\n      <td>(FNH2, GLA2, KLO2, LAG3, SLF2, STN2, TRU2)</td>\n      <td>[0.2729203701019287, 0.9275749325752258]</td>\n      <td>{'FNH2': 0.56565034, 'GLA2': 0.51399, 'KLO2': ...</td>\n      <td>FNH2</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>8</td>\n      <td>[AMD2, FLU2, SHE2, GUT2, ARO3, BOR2, TUM2, SPN...</td>\n      <td>(GLA2, KLO2, LAG3, SLF2, STN2, TRU2)</td>\n      <td>[0.2737712562084198, 0.9303604960441589]</td>\n      <td>{'GLA2': 0.4401654, 'KLO2': 0.44279513, 'LAG3'...</td>\n      <td>SLF2</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>9</td>\n      <td>[AMD2, FLU2, SHE2, GUT2, ARO3, BOR2, TUM2, SPN...</td>\n      <td>(GLA2, KLO2, LAG3, STN2, TRU2)</td>\n      <td>[0.3208243250846863, 0.9254915714263916]</td>\n      <td>{'GLA2': 0.43723786, 'KLO2': 0.4470492, 'LAG3'...</td>\n      <td>LAG3</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>10</td>\n      <td>[AMD2, FLU2, SHE2, GUT2, ARO3, BOR2, TUM2, SPN...</td>\n      <td>(GLA2, KLO2, STN2, TRU2)</td>\n      <td>[0.31596946716308594, 0.9263811111450195]</td>\n      <td>{'GLA2': 0.36698827, 'KLO2': 0.4165741, 'STN2'...</td>\n      <td>STN2</td>\n    </tr>\n    <tr>\n      <th>11</th>\n      <td>11</td>\n      <td>[AMD2, FLU2, SHE2, GUT2, ARO3, BOR2, TUM2, SPN...</td>\n      <td>(GLA2, KLO2, TRU2)</td>\n      <td>[0.27117809653282166, 0.9332162737846375]</td>\n      <td>{'GLA2': 0.30344704, 'KLO2': 0.36707085, 'TRU2...</td>\n      <td>KLO2</td>\n    </tr>\n    <tr>\n      <th>12</th>\n      <td>12</td>\n      <td>[AMD2, FLU2, SHE2, GUT2, ARO3, BOR2, TUM2, SPN...</td>\n      <td>(GLA2, TRU2)</td>\n      <td>[0.2791396677494049, 0.9313904643058777]</td>\n      <td>{'GLA2': 0.26802, 'TRU2': 0.24032019}</td>\n      <td>GLA2</td>\n    </tr>\n    <tr>\n      <th>13</th>\n      <td>13</td>\n      <td>[AMD2, FLU2, SHE2, GUT2, ARO3, BOR2, TUM2, SPN...</td>\n      <td>(TRU2)</td>\n      <td>[0.27906256914138794, 0.935486912727356]</td>\n      <td>{'TRU2': 0.29970127}</td>\n      <td>TRU2</td>\n    </tr>\n    <tr>\n      <th>14</th>\n      <td>14</td>\n      <td>[AMD2, FLU2, SHE2, GUT2, ARO3, BOR2, TUM2, SPN...</td>\n      <td>()</td>\n      <td>[0.2815271019935608, 0.9363998174667358]</td>\n      <td>{}</td>\n      <td>None</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary = pd.DataFrame(summary)\n",
    "summary"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-02T11:13:31.263877964Z",
     "start_time": "2023-11-02T11:13:31.168183873Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [],
   "source": [
    "! mkdir '2023-11-02_12-00-00_active_learning_results'\n",
    "# save results to txt\n",
    "summary.to_csv('./2023-11-02_12-00-00_active_learning_results/summary.csv', index=False)\n",
    "# save output to txt"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-02T11:13:56.467138615Z",
     "start_time": "2023-11-02T11:13:55.542159525Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "outputs": [],
   "source": [
    "model.save('./2023-11-02_12-00-00_active_learning_results/model.keras')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-02T11:14:11.050427290Z",
     "start_time": "2023-11-02T11:14:11.003677061Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'keras.layers.rnn.lstm.LSTM'> 128 <function tanh at 0x7f9a3302d040> True\r\n",
      "<class '__main__.MonteCarloDropout'> 0.5\r\n",
      "<class 'keras.layers.rnn.lstm.LSTM'> 64 <function tanh at 0x7f9a3302d040> False\r\n",
      "<class '__main__.MonteCarloDropout'> 0.5\r\n",
      "<class 'keras.layers.core.dense.Dense'> 8 <function relu at 0x7f9a33029ca0>\r\n",
      "<class 'keras.layers.core.dense.Dense'> 1 <function sigmoid at 0x7f9a3302d1f0>\r\n",
      "====================================================\r\n",
      "Active Learning Iteration #0\r\n",
      "Current Training Stations: ['AMD2']\r\n",
      "Epoch 1/10\r\n",
      "58/58 [==============================] - 7s 46ms/step - loss: 0.2352 - accuracy: 0.9150 - val_loss: 0.1331 - val_accuracy: 0.9479\r\n",
      "Epoch 2/10\r\n",
      "58/58 [==============================] - 2s 27ms/step - loss: 0.1621 - accuracy: 0.9296 - val_loss: 0.1250 - val_accuracy: 0.9457\r\n",
      "Epoch 3/10\r\n",
      "58/58 [==============================] - 2s 33ms/step - loss: 0.1532 - accuracy: 0.9315 - val_loss: 0.1318 - val_accuracy: 0.9319\r\n",
      "Epoch 4/10\r\n",
      "58/58 [==============================] - 2s 29ms/step - loss: 0.1466 - accuracy: 0.9323 - val_loss: 0.1146 - val_accuracy: 0.9594\r\n",
      "Epoch 5/10\r\n",
      "58/58 [==============================] - 2s 27ms/step - loss: 0.1440 - accuracy: 0.9367 - val_loss: 0.1075 - val_accuracy: 0.9610\r\n",
      "Epoch 6/10\r\n",
      "58/58 [==============================] - 2s 26ms/step - loss: 0.1411 - accuracy: 0.9380 - val_loss: 0.1098 - val_accuracy: 0.9638\r\n",
      "Epoch 7/10\r\n",
      "58/58 [==============================] - 2s 27ms/step - loss: 0.1369 - accuracy: 0.9394 - val_loss: 0.1067 - val_accuracy: 0.9660\r\n",
      "Epoch 8/10\r\n",
      "58/58 [==============================] - 2s 28ms/step - loss: 0.1306 - accuracy: 0.9392 - val_loss: 0.1009 - val_accuracy: 0.9698\r\n",
      "Epoch 9/10\r\n",
      "58/58 [==============================] - 2s 27ms/step - loss: 0.1305 - accuracy: 0.9413 - val_loss: 0.1054 - val_accuracy: 0.9616\r\n",
      "Epoch 10/10\r\n",
      "58/58 [==============================] - 2s 27ms/step - loss: 0.1304 - accuracy: 0.9432 - val_loss: 0.1048 - val_accuracy: 0.9649\r\n",
      "Evaluation model on out of sample data...\r\n",
      "334/334 [==============================] - 7s 19ms/step - loss: 0.2808 - accuracy: 0.9121\r\n",
      "Calculating uncertainty scores...\r\n",
      "Most uncertain FLU2\r\n",
      "====================================================\r\n",
      "Active Learning Iteration #1\r\n",
      "Current Training Stations: ['AMD2', 'FLU2']\r\n",
      "Epoch 1/10\r\n",
      "102/102 [==============================] - 2s 22ms/step - loss: 0.1525 - accuracy: 0.9427 - val_loss: 0.1429 - val_accuracy: 0.9438\r\n",
      "Epoch 2/10\r\n",
      "102/102 [==============================] - 2s 21ms/step - loss: 0.1501 - accuracy: 0.9437 - val_loss: 0.1482 - val_accuracy: 0.9450\r\n",
      "Epoch 3/10\r\n",
      "102/102 [==============================] - 2s 22ms/step - loss: 0.1435 - accuracy: 0.9462 - val_loss: 0.1363 - val_accuracy: 0.9515\r\n",
      "Epoch 4/10\r\n",
      "102/102 [==============================] - 2s 21ms/step - loss: 0.1432 - accuracy: 0.9455 - val_loss: 0.1330 - val_accuracy: 0.9506\r\n",
      "Epoch 5/10\r\n",
      "102/102 [==============================] - 2s 22ms/step - loss: 0.1402 - accuracy: 0.9455 - val_loss: 0.1491 - val_accuracy: 0.9422\r\n",
      "Epoch 6/10\r\n",
      "102/102 [==============================] - 3s 24ms/step - loss: 0.1349 - accuracy: 0.9491 - val_loss: 0.1370 - val_accuracy: 0.9484\r\n",
      "Epoch 7/10\r\n",
      "102/102 [==============================] - 2s 23ms/step - loss: 0.1320 - accuracy: 0.9500 - val_loss: 0.1494 - val_accuracy: 0.9410\r\n",
      "Epoch 8/10\r\n",
      "102/102 [==============================] - 3s 26ms/step - loss: 0.1320 - accuracy: 0.9491 - val_loss: 0.1631 - val_accuracy: 0.9317\r\n",
      "Epoch 9/10\r\n",
      "102/102 [==============================] - 3s 28ms/step - loss: 0.1285 - accuracy: 0.9498 - val_loss: 0.1566 - val_accuracy: 0.9354\r\n",
      "Epoch 10/10\r\n",
      "102/102 [==============================] - 3s 27ms/step - loss: 0.1257 - accuracy: 0.9509 - val_loss: 0.1365 - val_accuracy: 0.9493\r\n",
      "Evaluation model on out of sample data...\r\n",
      "334/334 [==============================] - 6s 18ms/step - loss: 0.2728 - accuracy: 0.9170\r\n",
      "Calculating uncertainty scores...\r\n",
      "Most uncertain SHE2\r\n",
      "====================================================\r\n",
      "Active Learning Iteration #2\r\n",
      "Current Training Stations: ['AMD2', 'FLU2', 'SHE2']\r\n",
      "Epoch 1/10\r\n",
      "151/151 [==============================] - 4s 27ms/step - loss: 0.1321 - accuracy: 0.9518 - val_loss: 0.1540 - val_accuracy: 0.9399\r\n",
      "Epoch 2/10\r\n",
      "151/151 [==============================] - 4s 27ms/step - loss: 0.1284 - accuracy: 0.9511 - val_loss: 0.1419 - val_accuracy: 0.9458\r\n",
      "Epoch 3/10\r\n",
      "151/151 [==============================] - 4s 26ms/step - loss: 0.1239 - accuracy: 0.9532 - val_loss: 0.1490 - val_accuracy: 0.9458\r\n",
      "Epoch 4/10\r\n",
      "151/151 [==============================] - 4s 27ms/step - loss: 0.1251 - accuracy: 0.9539 - val_loss: 0.1437 - val_accuracy: 0.9474\r\n",
      "Epoch 5/10\r\n",
      "151/151 [==============================] - 4s 27ms/step - loss: 0.1236 - accuracy: 0.9543 - val_loss: 0.1507 - val_accuracy: 0.9428\r\n",
      "Epoch 6/10\r\n",
      "151/151 [==============================] - 4s 28ms/step - loss: 0.1190 - accuracy: 0.9554 - val_loss: 0.1567 - val_accuracy: 0.9449\r\n",
      "Epoch 7/10\r\n",
      "151/151 [==============================] - 4s 26ms/step - loss: 0.1186 - accuracy: 0.9561 - val_loss: 0.1556 - val_accuracy: 0.9445\r\n",
      "Epoch 8/10\r\n",
      "151/151 [==============================] - 4s 26ms/step - loss: 0.1162 - accuracy: 0.9566 - val_loss: 0.1597 - val_accuracy: 0.9441\r\n",
      "Epoch 9/10\r\n",
      "151/151 [==============================] - 4s 25ms/step - loss: 0.1169 - accuracy: 0.9558 - val_loss: 0.1442 - val_accuracy: 0.9464\r\n",
      "Epoch 10/10\r\n",
      "151/151 [==============================] - 4s 27ms/step - loss: 0.1148 - accuracy: 0.9559 - val_loss: 0.1672 - val_accuracy: 0.9441\r\n",
      "Evaluation model on out of sample data...\r\n",
      "334/334 [==============================] - 6s 19ms/step - loss: 0.2528 - accuracy: 0.9243\r\n",
      "Calculating uncertainty scores...\r\n",
      "Most uncertain GUT2\r\n",
      "====================================================\r\n",
      "Active Learning Iteration #3\r\n",
      "Current Training Stations: ['AMD2', 'FLU2', 'SHE2', 'GUT2']\r\n",
      "Epoch 1/10\r\n",
      "204/204 [==============================] - 6s 27ms/step - loss: 0.1227 - accuracy: 0.9551 - val_loss: 0.1494 - val_accuracy: 0.9490\r\n",
      "Epoch 2/10\r\n",
      "204/204 [==============================] - 5s 21ms/step - loss: 0.1167 - accuracy: 0.9574 - val_loss: 0.1571 - val_accuracy: 0.9458\r\n",
      "Epoch 3/10\r\n",
      "204/204 [==============================] - 5s 25ms/step - loss: 0.1147 - accuracy: 0.9581 - val_loss: 0.1486 - val_accuracy: 0.9481\r\n",
      "Epoch 4/10\r\n",
      "204/204 [==============================] - 6s 28ms/step - loss: 0.1135 - accuracy: 0.9584 - val_loss: 0.1485 - val_accuracy: 0.9489\r\n",
      "Epoch 5/10\r\n",
      "204/204 [==============================] - 6s 28ms/step - loss: 0.1118 - accuracy: 0.9594 - val_loss: 0.1494 - val_accuracy: 0.9510\r\n",
      "Epoch 6/10\r\n",
      "204/204 [==============================] - 6s 29ms/step - loss: 0.1111 - accuracy: 0.9594 - val_loss: 0.1475 - val_accuracy: 0.9476\r\n",
      "Epoch 7/10\r\n",
      "204/204 [==============================] - 6s 27ms/step - loss: 0.1092 - accuracy: 0.9605 - val_loss: 0.1502 - val_accuracy: 0.9509\r\n",
      "Epoch 8/10\r\n",
      "204/204 [==============================] - 6s 27ms/step - loss: 0.1079 - accuracy: 0.9615 - val_loss: 0.1551 - val_accuracy: 0.9480\r\n",
      "Epoch 9/10\r\n",
      "204/204 [==============================] - 6s 29ms/step - loss: 0.1055 - accuracy: 0.9619 - val_loss: 0.1522 - val_accuracy: 0.9483\r\n",
      "Epoch 10/10\r\n",
      "204/204 [==============================] - 6s 29ms/step - loss: 0.1095 - accuracy: 0.9606 - val_loss: 0.1577 - val_accuracy: 0.9501\r\n",
      "Evaluation model on out of sample data...\r\n",
      "334/334 [==============================] - 7s 19ms/step - loss: 0.2504 - accuracy: 0.9054\r\n",
      "Calculating uncertainty scores...\r\n",
      "Most uncertain ARO3\r\n",
      "====================================================\r\n",
      "Active Learning Iteration #4\r\n",
      "Current Training Stations: ['AMD2', 'FLU2', 'SHE2', 'GUT2', 'ARO3']\r\n",
      "Epoch 1/10\r\n",
      "264/264 [==============================] - 6s 23ms/step - loss: 0.1175 - accuracy: 0.9557 - val_loss: 0.1513 - val_accuracy: 0.9476\r\n",
      "Epoch 2/10\r\n",
      "264/264 [==============================] - 6s 21ms/step - loss: 0.1151 - accuracy: 0.9575 - val_loss: 0.1601 - val_accuracy: 0.9456\r\n",
      "Epoch 3/10\r\n",
      "264/264 [==============================] - 6s 21ms/step - loss: 0.1132 - accuracy: 0.9574 - val_loss: 0.1509 - val_accuracy: 0.9463\r\n",
      "Epoch 4/10\r\n",
      "264/264 [==============================] - 6s 21ms/step - loss: 0.1146 - accuracy: 0.9569 - val_loss: 0.1526 - val_accuracy: 0.9455\r\n",
      "Epoch 5/10\r\n",
      "264/264 [==============================] - 6s 21ms/step - loss: 0.1130 - accuracy: 0.9577 - val_loss: 0.1444 - val_accuracy: 0.9460\r\n",
      "Epoch 6/10\r\n",
      "264/264 [==============================] - 7s 25ms/step - loss: 0.1110 - accuracy: 0.9587 - val_loss: 0.1521 - val_accuracy: 0.9453\r\n",
      "Epoch 7/10\r\n",
      "264/264 [==============================] - 7s 27ms/step - loss: 0.1146 - accuracy: 0.9564 - val_loss: 0.1494 - val_accuracy: 0.9455\r\n",
      "Epoch 8/10\r\n",
      "264/264 [==============================] - 8s 28ms/step - loss: 0.1095 - accuracy: 0.9592 - val_loss: 0.1609 - val_accuracy: 0.9472\r\n",
      "Epoch 9/10\r\n",
      "264/264 [==============================] - 9s 32ms/step - loss: 0.1089 - accuracy: 0.9589 - val_loss: 0.1522 - val_accuracy: 0.9466\r\n",
      "Epoch 10/10\r\n",
      "264/264 [==============================] - 6s 23ms/step - loss: 0.1090 - accuracy: 0.9589 - val_loss: 0.1545 - val_accuracy: 0.9476\r\n",
      "Evaluation model on out of sample data...\r\n",
      "334/334 [==============================] - 6s 18ms/step - loss: 0.2599 - accuracy: 0.9141\r\n",
      "Calculating uncertainty scores...\r\n",
      "Most uncertain BOR2\r\n",
      "====================================================\r\n",
      "Active Learning Iteration #5\r\n",
      "Current Training Stations: ['AMD2', 'FLU2', 'SHE2', 'GUT2', 'ARO3', 'BOR2']\r\n",
      "Epoch 1/10\r\n",
      "313/313 [==============================] - 7s 22ms/step - loss: 0.1050 - accuracy: 0.9608 - val_loss: 0.1341 - val_accuracy: 0.9515\r\n",
      "Epoch 2/10\r\n",
      "313/313 [==============================] - 9s 27ms/step - loss: 0.1036 - accuracy: 0.9618 - val_loss: 0.1404 - val_accuracy: 0.9522\r\n",
      "Epoch 3/10\r\n",
      "313/313 [==============================] - 8s 26ms/step - loss: 0.1017 - accuracy: 0.9614 - val_loss: 0.1440 - val_accuracy: 0.9493\r\n",
      "Epoch 4/10\r\n",
      "313/313 [==============================] - 9s 29ms/step - loss: 0.1020 - accuracy: 0.9610 - val_loss: 0.1457 - val_accuracy: 0.9503\r\n",
      "Epoch 5/10\r\n",
      "313/313 [==============================] - 9s 27ms/step - loss: 0.1023 - accuracy: 0.9615 - val_loss: 0.1468 - val_accuracy: 0.9525\r\n",
      "Epoch 6/10\r\n",
      "313/313 [==============================] - 8s 26ms/step - loss: 0.1014 - accuracy: 0.9612 - val_loss: 0.1388 - val_accuracy: 0.9523\r\n",
      "Epoch 7/10\r\n",
      "313/313 [==============================] - 7s 22ms/step - loss: 0.0963 - accuracy: 0.9640 - val_loss: 0.1451 - val_accuracy: 0.9505\r\n",
      "Epoch 8/10\r\n",
      "313/313 [==============================] - 7s 22ms/step - loss: 0.0970 - accuracy: 0.9637 - val_loss: 0.1384 - val_accuracy: 0.9507\r\n",
      "Epoch 9/10\r\n",
      "313/313 [==============================] - 8s 26ms/step - loss: 0.0940 - accuracy: 0.9649 - val_loss: 0.1430 - val_accuracy: 0.9514\r\n",
      "Epoch 10/10\r\n",
      "313/313 [==============================] - 8s 26ms/step - loss: 0.0945 - accuracy: 0.9641 - val_loss: 0.1493 - val_accuracy: 0.9511\r\n",
      "Evaluation model on out of sample data...\r\n",
      "334/334 [==============================] - 7s 19ms/step - loss: 0.2418 - accuracy: 0.9254\r\n",
      "Calculating uncertainty scores...\r\n",
      "Most uncertain TUM2\r\n",
      "====================================================\r\n",
      "Active Learning Iteration #6\r\n",
      "Current Training Stations: ['AMD2', 'FLU2', 'SHE2', 'GUT2', 'ARO3', 'BOR2', 'TUM2']\r\n",
      "Epoch 1/10\r\n",
      "359/359 [==============================] - 10s 26ms/step - loss: 0.0945 - accuracy: 0.9654 - val_loss: 0.1433 - val_accuracy: 0.9504\r\n",
      "Epoch 2/10\r\n",
      "359/359 [==============================] - 10s 26ms/step - loss: 0.0900 - accuracy: 0.9671 - val_loss: 0.1322 - val_accuracy: 0.9533\r\n",
      "Epoch 3/10\r\n",
      "359/359 [==============================] - 11s 29ms/step - loss: 0.0889 - accuracy: 0.9672 - val_loss: 0.1348 - val_accuracy: 0.9537\r\n",
      "Epoch 4/10\r\n",
      "359/359 [==============================] - 9s 24ms/step - loss: 0.0888 - accuracy: 0.9674 - val_loss: 0.1369 - val_accuracy: 0.9520\r\n",
      "Epoch 5/10\r\n",
      "359/359 [==============================] - 9s 24ms/step - loss: 0.0882 - accuracy: 0.9670 - val_loss: 0.1321 - val_accuracy: 0.9531\r\n",
      "Epoch 6/10\r\n",
      "359/359 [==============================] - 10s 27ms/step - loss: 0.0859 - accuracy: 0.9684 - val_loss: 0.1409 - val_accuracy: 0.9517\r\n",
      "Epoch 7/10\r\n",
      "359/359 [==============================] - 11s 29ms/step - loss: 0.0844 - accuracy: 0.9689 - val_loss: 0.1338 - val_accuracy: 0.9537\r\n",
      "Epoch 8/10\r\n",
      "359/359 [==============================] - 9s 24ms/step - loss: 0.0843 - accuracy: 0.9684 - val_loss: 0.1417 - val_accuracy: 0.9545\r\n",
      "Epoch 9/10\r\n",
      "359/359 [==============================] - 8s 23ms/step - loss: 0.0828 - accuracy: 0.9691 - val_loss: 0.1370 - val_accuracy: 0.9531\r\n",
      "Epoch 10/10\r\n",
      "359/359 [==============================] - 10s 27ms/step - loss: 0.0850 - accuracy: 0.9686 - val_loss: 0.1325 - val_accuracy: 0.9532\r\n",
      "Evaluation model on out of sample data...\r\n",
      "334/334 [==============================] - 7s 19ms/step - loss: 0.2499 - accuracy: 0.9281\r\n",
      "Calculating uncertainty scores...\r\n",
      "Most uncertain SPN2\r\n",
      "====================================================\r\n",
      "Active Learning Iteration #7\r\n",
      "Current Training Stations: ['AMD2', 'FLU2', 'SHE2', 'GUT2', 'ARO3', 'BOR2', 'TUM2', 'SPN2']\r\n",
      "Epoch 1/10\r\n",
      "419/419 [==============================] - 12s 29ms/step - loss: 0.1188 - accuracy: 0.9568 - val_loss: 0.1405 - val_accuracy: 0.9486\r\n",
      "Epoch 2/10\r\n",
      "419/419 [==============================] - 12s 27ms/step - loss: 0.1103 - accuracy: 0.9586 - val_loss: 0.1369 - val_accuracy: 0.9483\r\n",
      "Epoch 3/10\r\n",
      "419/419 [==============================] - 12s 28ms/step - loss: 0.1064 - accuracy: 0.9601 - val_loss: 0.1386 - val_accuracy: 0.9471\r\n",
      "Epoch 4/10\r\n",
      "419/419 [==============================] - 9s 21ms/step - loss: 0.1067 - accuracy: 0.9597 - val_loss: 0.1429 - val_accuracy: 0.9478\r\n",
      "Epoch 5/10\r\n",
      "419/419 [==============================] - 11s 25ms/step - loss: 0.1039 - accuracy: 0.9619 - val_loss: 0.1548 - val_accuracy: 0.9450\r\n",
      "Epoch 6/10\r\n",
      "419/419 [==============================] - 11s 26ms/step - loss: 0.1019 - accuracy: 0.9623 - val_loss: 0.1530 - val_accuracy: 0.9429\r\n",
      "Epoch 7/10\r\n",
      "419/419 [==============================] - 11s 27ms/step - loss: 0.0994 - accuracy: 0.9632 - val_loss: 0.1542 - val_accuracy: 0.9440\r\n",
      "Epoch 8/10\r\n",
      "419/419 [==============================] - 11s 26ms/step - loss: 0.0964 - accuracy: 0.9648 - val_loss: 0.1477 - val_accuracy: 0.9493\r\n",
      "Epoch 9/10\r\n",
      "419/419 [==============================] - 11s 26ms/step - loss: 0.0970 - accuracy: 0.9650 - val_loss: 0.1496 - val_accuracy: 0.9455\r\n",
      "Epoch 10/10\r\n",
      "419/419 [==============================] - 11s 27ms/step - loss: 0.0952 - accuracy: 0.9651 - val_loss: 0.1558 - val_accuracy: 0.9470\r\n",
      "Evaluation model on out of sample data...\r\n",
      "334/334 [==============================] - 6s 18ms/step - loss: 0.2729 - accuracy: 0.9276\r\n",
      "Calculating uncertainty scores...\r\n",
      "Most uncertain FNH2\r\n",
      "====================================================\r\n",
      "Active Learning Iteration #8\r\n",
      "Current Training Stations: ['AMD2', 'FLU2', 'SHE2', 'GUT2', 'ARO3', 'BOR2', 'TUM2', 'SPN2', 'FNH2']\r\n",
      "Epoch 1/10\r\n",
      "477/477 [==============================] - 11s 22ms/step - loss: 0.0943 - accuracy: 0.9656 - val_loss: 0.1400 - val_accuracy: 0.9484\r\n",
      "Epoch 2/10\r\n",
      "477/477 [==============================] - 10s 21ms/step - loss: 0.0917 - accuracy: 0.9664 - val_loss: 0.1440 - val_accuracy: 0.9494\r\n",
      "Epoch 3/10\r\n",
      "477/477 [==============================] - 13s 27ms/step - loss: 0.0887 - accuracy: 0.9675 - val_loss: 0.1507 - val_accuracy: 0.9484\r\n",
      "Epoch 4/10\r\n",
      "477/477 [==============================] - 13s 28ms/step - loss: 0.0894 - accuracy: 0.9671 - val_loss: 0.1411 - val_accuracy: 0.9485\r\n",
      "Epoch 5/10\r\n",
      "477/477 [==============================] - 13s 27ms/step - loss: 0.0862 - accuracy: 0.9678 - val_loss: 0.1406 - val_accuracy: 0.9501\r\n",
      "Epoch 6/10\r\n",
      "477/477 [==============================] - 13s 27ms/step - loss: 0.0831 - accuracy: 0.9692 - val_loss: 0.1478 - val_accuracy: 0.9482\r\n",
      "Epoch 7/10\r\n",
      "477/477 [==============================] - 13s 27ms/step - loss: 0.0835 - accuracy: 0.9690 - val_loss: 0.1533 - val_accuracy: 0.9478\r\n",
      "Epoch 8/10\r\n",
      "477/477 [==============================] - 13s 27ms/step - loss: 0.0828 - accuracy: 0.9688 - val_loss: 0.1503 - val_accuracy: 0.9484\r\n",
      "Epoch 9/10\r\n",
      "477/477 [==============================] - 13s 27ms/step - loss: 0.0810 - accuracy: 0.9697 - val_loss: 0.1502 - val_accuracy: 0.9471\r\n",
      "Epoch 10/10\r\n",
      "477/477 [==============================] - 13s 26ms/step - loss: 0.0776 - accuracy: 0.9708 - val_loss: 0.1538 - val_accuracy: 0.9487\r\n",
      "Evaluation model on out of sample data...\r\n",
      "334/334 [==============================] - 6s 19ms/step - loss: 0.2738 - accuracy: 0.9304\r\n",
      "Calculating uncertainty scores...\r\n",
      "Most uncertain SLF2\r\n",
      "====================================================\r\n",
      "Active Learning Iteration #9\r\n",
      "Current Training Stations: ['AMD2', 'FLU2', 'SHE2', 'GUT2', 'ARO3', 'BOR2', 'TUM2', 'SPN2', 'FNH2', 'SLF2']\r\n",
      "Epoch 1/10\r\n",
      "535/535 [==============================] - 12s 21ms/step - loss: 0.0975 - accuracy: 0.9646 - val_loss: 0.1396 - val_accuracy: 0.9492\r\n",
      "Epoch 2/10\r\n",
      "535/535 [==============================] - 14s 27ms/step - loss: 0.0880 - accuracy: 0.9675 - val_loss: 0.1327 - val_accuracy: 0.9518\r\n",
      "Epoch 3/10\r\n",
      "535/535 [==============================] - 14s 26ms/step - loss: 0.0821 - accuracy: 0.9693 - val_loss: 0.1365 - val_accuracy: 0.9495\r\n",
      "Epoch 4/10\r\n",
      "535/535 [==============================] - 14s 26ms/step - loss: 0.0808 - accuracy: 0.9696 - val_loss: 0.1297 - val_accuracy: 0.9522\r\n",
      "Epoch 5/10\r\n",
      "535/535 [==============================] - 14s 26ms/step - loss: 0.0812 - accuracy: 0.9696 - val_loss: 0.1339 - val_accuracy: 0.9523\r\n",
      "Epoch 6/10\r\n",
      "535/535 [==============================] - 12s 22ms/step - loss: 0.0746 - accuracy: 0.9725 - val_loss: 0.1366 - val_accuracy: 0.9523\r\n",
      "Epoch 7/10\r\n",
      "535/535 [==============================] - 14s 27ms/step - loss: 0.0746 - accuracy: 0.9727 - val_loss: 0.1408 - val_accuracy: 0.9497\r\n",
      "Epoch 8/10\r\n",
      "535/535 [==============================] - 14s 26ms/step - loss: 0.0741 - accuracy: 0.9723 - val_loss: 0.1420 - val_accuracy: 0.9503\r\n",
      "Epoch 9/10\r\n",
      "535/535 [==============================] - 14s 25ms/step - loss: 0.0715 - accuracy: 0.9733 - val_loss: 0.1422 - val_accuracy: 0.9513\r\n",
      "Epoch 10/10\r\n",
      "535/535 [==============================] - 15s 27ms/step - loss: 0.0714 - accuracy: 0.9731 - val_loss: 0.1411 - val_accuracy: 0.9508\r\n",
      "Evaluation model on out of sample data...\r\n",
      "334/334 [==============================] - 6s 18ms/step - loss: 0.3208 - accuracy: 0.9255\r\n",
      "Calculating uncertainty scores...\r\n",
      "Most uncertain LAG3\r\n",
      "====================================================\r\n",
      "Active Learning Iteration #10\r\n",
      "Current Training Stations: ['AMD2', 'FLU2', 'SHE2', 'GUT2', 'ARO3', 'BOR2', 'TUM2', 'SPN2', 'FNH2', 'SLF2', 'LAG3']\r\n",
      "Epoch 1/10\r\n",
      "565/565 [==============================] - 16s 28ms/step - loss: 0.0733 - accuracy: 0.9740 - val_loss: 0.1377 - val_accuracy: 0.9513\r\n",
      "Epoch 2/10\r\n",
      "565/565 [==============================] - 16s 27ms/step - loss: 0.0747 - accuracy: 0.9732 - val_loss: 0.1400 - val_accuracy: 0.9477\r\n",
      "Epoch 3/10\r\n",
      "565/565 [==============================] - 16s 28ms/step - loss: 0.0722 - accuracy: 0.9739 - val_loss: 0.1417 - val_accuracy: 0.9506\r\n",
      "Epoch 4/10\r\n",
      "565/565 [==============================] - 16s 28ms/step - loss: 0.0692 - accuracy: 0.9747 - val_loss: 0.1450 - val_accuracy: 0.9499\r\n",
      "Epoch 5/10\r\n",
      "565/565 [==============================] - 16s 28ms/step - loss: 0.0686 - accuracy: 0.9752 - val_loss: 0.1447 - val_accuracy: 0.9493\r\n",
      "Epoch 6/10\r\n",
      "565/565 [==============================] - 15s 26ms/step - loss: 0.0686 - accuracy: 0.9758 - val_loss: 0.1444 - val_accuracy: 0.9520\r\n",
      "Epoch 7/10\r\n",
      "565/565 [==============================] - 15s 27ms/step - loss: 0.0705 - accuracy: 0.9749 - val_loss: 0.1434 - val_accuracy: 0.9503\r\n",
      "Epoch 8/10\r\n",
      "565/565 [==============================] - 14s 24ms/step - loss: 0.0662 - accuracy: 0.9763 - val_loss: 0.1487 - val_accuracy: 0.9515\r\n",
      "Epoch 9/10\r\n",
      "565/565 [==============================] - 15s 26ms/step - loss: 0.0640 - accuracy: 0.9772 - val_loss: 0.1509 - val_accuracy: 0.9506\r\n",
      "Epoch 10/10\r\n",
      "565/565 [==============================] - 15s 27ms/step - loss: 0.0701 - accuracy: 0.9742 - val_loss: 0.1471 - val_accuracy: 0.9477\r\n",
      "Evaluation model on out of sample data...\r\n",
      "334/334 [==============================] - 6s 19ms/step - loss: 0.3160 - accuracy: 0.9264\r\n",
      "Calculating uncertainty scores...\r\n",
      "Most uncertain STN2\r\n",
      "====================================================\r\n",
      "Active Learning Iteration #11\r\n",
      "Current Training Stations: ['AMD2', 'FLU2', 'SHE2', 'GUT2', 'ARO3', 'BOR2', 'TUM2', 'SPN2', 'FNH2', 'SLF2', 'LAG3', 'STN2']\r\n",
      "Epoch 1/10\r\n",
      "621/621 [==============================] - 15s 24ms/step - loss: 0.0751 - accuracy: 0.9733 - val_loss: 0.1427 - val_accuracy: 0.9484\r\n",
      "Epoch 2/10\r\n",
      "621/621 [==============================] - 17s 26ms/step - loss: 0.0685 - accuracy: 0.9752 - val_loss: 0.1440 - val_accuracy: 0.9482\r\n",
      "Epoch 3/10\r\n",
      "621/621 [==============================] - 17s 27ms/step - loss: 0.0689 - accuracy: 0.9750 - val_loss: 0.1548 - val_accuracy: 0.9483\r\n",
      "Epoch 4/10\r\n",
      "621/621 [==============================] - 17s 27ms/step - loss: 0.0665 - accuracy: 0.9762 - val_loss: 0.1479 - val_accuracy: 0.9512\r\n",
      "Epoch 5/10\r\n",
      "621/621 [==============================] - 17s 27ms/step - loss: 0.0749 - accuracy: 0.9725 - val_loss: 0.1307 - val_accuracy: 0.9523\r\n",
      "Epoch 6/10\r\n",
      "621/621 [==============================] - 15s 23ms/step - loss: 0.0718 - accuracy: 0.9740 - val_loss: 0.1479 - val_accuracy: 0.9464\r\n",
      "Epoch 7/10\r\n",
      "621/621 [==============================] - 15s 24ms/step - loss: 0.0669 - accuracy: 0.9763 - val_loss: 0.1442 - val_accuracy: 0.9495\r\n",
      "Epoch 8/10\r\n",
      "621/621 [==============================] - 16s 26ms/step - loss: 0.0659 - accuracy: 0.9759 - val_loss: 0.1476 - val_accuracy: 0.9495\r\n",
      "Epoch 9/10\r\n",
      "621/621 [==============================] - 18s 28ms/step - loss: 0.0645 - accuracy: 0.9771 - val_loss: 0.1493 - val_accuracy: 0.9499\r\n",
      "Epoch 10/10\r\n",
      "621/621 [==============================] - 18s 29ms/step - loss: 0.0618 - accuracy: 0.9776 - val_loss: 0.1425 - val_accuracy: 0.9505\r\n",
      "Evaluation model on out of sample data...\r\n",
      "334/334 [==============================] - 7s 20ms/step - loss: 0.2712 - accuracy: 0.9332\r\n",
      "Calculating uncertainty scores...\r\n",
      "Most uncertain KLO2\r\n",
      "====================================================\r\n",
      "Active Learning Iteration #12\r\n",
      "Current Training Stations: ['AMD2', 'FLU2', 'SHE2', 'GUT2', 'ARO3', 'BOR2', 'TUM2', 'SPN2', 'FNH2', 'SLF2', 'LAG3', 'STN2', 'KLO2']\r\n",
      "Epoch 1/10\r\n",
      "681/681 [==============================] - 18s 26ms/step - loss: 0.0658 - accuracy: 0.9766 - val_loss: 0.1342 - val_accuracy: 0.9554\r\n",
      "Epoch 2/10\r\n",
      "681/681 [==============================] - 18s 26ms/step - loss: 0.0643 - accuracy: 0.9768 - val_loss: 0.1378 - val_accuracy: 0.9533\r\n",
      "Epoch 3/10\r\n",
      "681/681 [==============================] - 16s 23ms/step - loss: 0.0663 - accuracy: 0.9759 - val_loss: 0.1421 - val_accuracy: 0.9501\r\n",
      "Epoch 4/10\r\n",
      "681/681 [==============================] - 18s 26ms/step - loss: 0.0624 - accuracy: 0.9774 - val_loss: 0.1470 - val_accuracy: 0.9503\r\n",
      "Epoch 5/10\r\n",
      "681/681 [==============================] - 18s 26ms/step - loss: 0.0640 - accuracy: 0.9763 - val_loss: 0.1403 - val_accuracy: 0.9536\r\n",
      "Epoch 6/10\r\n",
      "681/681 [==============================] - 18s 26ms/step - loss: 0.0614 - accuracy: 0.9778 - val_loss: 0.1393 - val_accuracy: 0.9528\r\n",
      "Epoch 7/10\r\n",
      "681/681 [==============================] - 18s 26ms/step - loss: 0.0615 - accuracy: 0.9775 - val_loss: 0.1471 - val_accuracy: 0.9494\r\n",
      "Epoch 8/10\r\n",
      "681/681 [==============================] - 18s 26ms/step - loss: 0.0607 - accuracy: 0.9783 - val_loss: 0.1390 - val_accuracy: 0.9526\r\n",
      "Epoch 9/10\r\n",
      "681/681 [==============================] - 17s 25ms/step - loss: 0.0589 - accuracy: 0.9785 - val_loss: 0.1508 - val_accuracy: 0.9522\r\n",
      "Epoch 10/10\r\n",
      "681/681 [==============================] - 17s 25ms/step - loss: 0.0585 - accuracy: 0.9788 - val_loss: 0.1591 - val_accuracy: 0.9475\r\n",
      "Evaluation model on out of sample data...\r\n",
      "334/334 [==============================] - 6s 17ms/step - loss: 0.2791 - accuracy: 0.9314\r\n",
      "Calculating uncertainty scores...\r\n",
      "Most uncertain GLA2\r\n",
      "====================================================\r\n",
      "Active Learning Iteration #13\r\n",
      "Current Training Stations: ['AMD2', 'FLU2', 'SHE2', 'GUT2', 'ARO3', 'BOR2', 'TUM2', 'SPN2', 'FNH2', 'SLF2', 'LAG3', 'STN2', 'KLO2', 'GLA2']\r\n",
      "Epoch 1/10\r\n",
      "731/731 [==============================] - 19s 26ms/step - loss: 0.0658 - accuracy: 0.9767 - val_loss: 0.1473 - val_accuracy: 0.9489\r\n",
      "Epoch 2/10\r\n",
      "731/731 [==============================] - 17s 23ms/step - loss: 0.0603 - accuracy: 0.9784 - val_loss: 0.1629 - val_accuracy: 0.9473\r\n",
      "Epoch 3/10\r\n",
      "731/731 [==============================] - 20s 27ms/step - loss: 0.0602 - accuracy: 0.9779 - val_loss: 0.1583 - val_accuracy: 0.9489\r\n",
      "Epoch 4/10\r\n",
      "731/731 [==============================] - 21s 28ms/step - loss: 0.0589 - accuracy: 0.9783 - val_loss: 0.1487 - val_accuracy: 0.9501\r\n",
      "Epoch 5/10\r\n",
      "731/731 [==============================] - 20s 27ms/step - loss: 0.0571 - accuracy: 0.9795 - val_loss: 0.1574 - val_accuracy: 0.9501\r\n",
      "Epoch 6/10\r\n",
      "731/731 [==============================] - 20s 27ms/step - loss: 0.0567 - accuracy: 0.9797 - val_loss: 0.1580 - val_accuracy: 0.9499\r\n",
      "Epoch 7/10\r\n",
      "731/731 [==============================] - 17s 24ms/step - loss: 0.0562 - accuracy: 0.9797 - val_loss: 0.1712 - val_accuracy: 0.9453\r\n",
      "Epoch 8/10\r\n",
      "731/731 [==============================] - 19s 26ms/step - loss: 0.0554 - accuracy: 0.9797 - val_loss: 0.1582 - val_accuracy: 0.9526\r\n",
      "Epoch 9/10\r\n",
      "731/731 [==============================] - 19s 26ms/step - loss: 0.0556 - accuracy: 0.9799 - val_loss: 0.1584 - val_accuracy: 0.9510\r\n",
      "Epoch 10/10\r\n",
      "731/731 [==============================] - 16s 22ms/step - loss: 0.0556 - accuracy: 0.9801 - val_loss: 0.1585 - val_accuracy: 0.9501\r\n",
      "Evaluation model on out of sample data...\r\n",
      "334/334 [==============================] - 6s 17ms/step - loss: 0.2791 - accuracy: 0.9355\r\n",
      "Calculating uncertainty scores...\r\n",
      "Most uncertain TRU2\r\n",
      "====================================================\r\n",
      "Active Learning Iteration #14\r\n",
      "Current Training Stations: ['AMD2', 'FLU2', 'SHE2', 'GUT2', 'ARO3', 'BOR2', 'TUM2', 'SPN2', 'FNH2', 'SLF2', 'LAG3', 'STN2', 'KLO2', 'GLA2', 'TRU2']\r\n",
      "Epoch 1/10\r\n",
      "791/791 [==============================] - 21s 26ms/step - loss: 0.0607 - accuracy: 0.9782 - val_loss: 0.1456 - val_accuracy: 0.9522\r\n",
      "Epoch 2/10\r\n",
      "791/791 [==============================] - 21s 27ms/step - loss: 0.0582 - accuracy: 0.9789 - val_loss: 0.1454 - val_accuracy: 0.9533\r\n",
      "Epoch 3/10\r\n",
      "791/791 [==============================] - 21s 27ms/step - loss: 0.0567 - accuracy: 0.9792 - val_loss: 0.1426 - val_accuracy: 0.9532\r\n",
      "Epoch 4/10\r\n",
      "791/791 [==============================] - 21s 26ms/step - loss: 0.0568 - accuracy: 0.9789 - val_loss: 0.1576 - val_accuracy: 0.9474\r\n",
      "Epoch 5/10\r\n",
      "791/791 [==============================] - 23s 29ms/step - loss: 0.0553 - accuracy: 0.9796 - val_loss: 0.1474 - val_accuracy: 0.9514\r\n",
      "Epoch 6/10\r\n",
      "791/791 [==============================] - 19s 24ms/step - loss: 0.0555 - accuracy: 0.9794 - val_loss: 0.1509 - val_accuracy: 0.9501\r\n",
      "Epoch 7/10\r\n",
      "791/791 [==============================] - 22s 28ms/step - loss: 0.0547 - accuracy: 0.9795 - val_loss: 0.1507 - val_accuracy: 0.9504\r\n",
      "Epoch 8/10\r\n",
      "791/791 [==============================] - 21s 26ms/step - loss: 0.0533 - accuracy: 0.9808 - val_loss: 0.1617 - val_accuracy: 0.9521\r\n",
      "Epoch 9/10\r\n",
      "791/791 [==============================] - 21s 27ms/step - loss: 0.0541 - accuracy: 0.9800 - val_loss: 0.1555 - val_accuracy: 0.9509\r\n",
      "Epoch 10/10\r\n",
      "791/791 [==============================] - 21s 27ms/step - loss: 0.0515 - accuracy: 0.9808 - val_loss: 0.1536 - val_accuracy: 0.9510\r\n",
      "Evaluation model on out of sample data...\r\n",
      "334/334 [==============================] - 7s 20ms/step - loss: 0.2815 - accuracy: 0.9364"
     ]
    }
   ],
   "source": [
    "! cat 2023-11-02_12-00-00_active_learning_results/output.txt"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-02T11:15:15.773509298Z",
     "start_time": "2023-11-02T11:15:14.887437879Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  adding: 2023-11-02_12-00-00_active_learning_results/ (stored 0%)\r\n",
      "  adding: 2023-11-02_12-00-00_active_learning_results/summary.csv (deflated 72%)\r\n",
      "  adding: 2023-11-02_12-00-00_active_learning_results/output.txt (deflated 88%)\r\n",
      "  adding: 2023-11-02_12-00-00_active_learning_results/model.keras (deflated 10%)\r\n",
      "  adding: 2023-11-02_12-00-00_active_learning_results/.ipynb_checkpoints/ (stored 0%)\r\n",
      "  adding: 2023-11-02_12-00-00_active_learning_results/.ipynb_checkpoints/output-checkpoint.txt (stored 0%)\r\n"
     ]
    }
   ],
   "source": [
    "! zip -r results.zip 2023-11-02_12-00-00_active_learning_results"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-02T13:03:17.434131157Z",
     "start_time": "2023-11-02T13:03:16.492080953Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
