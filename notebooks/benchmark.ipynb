{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "tags": [],
    "ExecuteTime": {
     "end_time": "2023-12-13T14:25:08.822413267Z",
     "start_time": "2023-12-13T14:25:08.713935445Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import os\n",
    "\n",
    "import mlflow\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import tensorflow as tf\n",
    "from dotenv import load_dotenv\n",
    "from keras.src.metrics import Recall, Precision\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "from src.functions import create_model, plot_data, check_gpus, load_stations_from_path, \\\n",
    "    create_test_datasets, plot_keras_history, preprocces, mlflow_log_np_as_file\n",
    "from src.utils import now_formatted, setup_logger, format_with_border, measure_execution_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-13T14:25:09.983061235Z",
     "start_time": "2023-12-13T14:25:09.923958766Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n",
      "1 Physical GPUs, 1 Logical GPUs\n"
     ]
    }
   ],
   "source": [
    "check_gpus()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "outputs": [],
   "source": [
    "load_dotenv()\n",
    "mlflow_port = os.getenv('MLFLOW_PORT')\n",
    "mlflow_uri = f'http://localhost:{mlflow_port}'\n",
    "mlflow_experiment_name = f'Benchmark'\n",
    "train_path = '../data/labeled_benchmark/train'\n",
    "test_path = '../data/labeled_benchmark/test'\n",
    "log_file_path = '/tmp/benchmark.log'\n",
    "\n",
    "mlflow.set_tracking_uri(mlflow_uri)\n",
    "mlflow.set_experiment(mlflow_experiment_name)\n",
    "mlflow.tensorflow.autolog()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-13T14:25:12.107796481Z",
     "start_time": "2023-12-13T14:25:12.061765282Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "outputs": [],
   "source": [
    "SEQUENCE_LENGTH = 50\n",
    "TARGET_START_INDEX = SEQUENCE_LENGTH - 1\n",
    "FEATURE_COLUMNS = [\n",
    "    'HS',\n",
    "    'day_sin',\n",
    "    'day_cos',\n",
    "    'month_sin',\n",
    "    'month_cos',\n",
    "    'TSS_30MIN_MEAN',\n",
    "    'RSWR_30MIN_MEAN',\n",
    "    'TA_30MIN_MEAN',\n",
    "    'VW_30MIN_MEAN'\n",
    "]\n",
    "TARGET_COLUMN = 'no_snow'\n",
    "DATE_COLUMN = 'measure_date'\n",
    "SPLIT_PERCENTAGE = 0.8\n",
    "DATASET_BATCH_SIZE = 64\n",
    "\n",
    "# Model configuration\n",
    "MODEL_ARCHITECTURE = \"128(l)-64-8(d)-1\"\n",
    "MODEL_INPUT_SHAPE = (SEQUENCE_LENGTH, len(FEATURE_COLUMNS))\n",
    "MODEL_DROPOUT_RATE = 0.5\n",
    "MODEL_OPTIMIZER = 'adam'\n",
    "MODEL_METRICS = ['accuracy', Recall(), Precision()],\n",
    "\n",
    "MODEL_LOSS = 'binary_crossentropy'\n",
    "MODEL_BATCH_SIZE = 64\n",
    "MODEL_EPOCHS = 15\n",
    "\n",
    "EXPERIMENT_NAME = 'TESTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTT'\n",
    "\n",
    "def log_parameters(logging, mlflow):\n",
    "    global_vars = globals()\n",
    "    for var_name, value in global_vars.items():\n",
    "        if var_name.isupper():\n",
    "            logging.info(f'{var_name}: {value}')\n",
    "            mlflow.log_param(f'benchmark_{var_name.lower()}', value)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-13T14:25:13.449621237Z",
     "start_time": "2023-12-13T14:25:13.387254936Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "outputs": [],
   "source": [
    "def generate_confusion_matrix():\n",
    "    y_true = [ts.loc[TARGET_START_INDEX:, 'no_snow'].values for ts in testing_stations.values()]\n",
    "    y_pred = [model.predict(td, verbose=0).reshape((-1,)) > 0.5 for td in test_datasets]\n",
    "    n_matrices = len(y_true)\n",
    "    n_cols = 3\n",
    "    n_rows = (n_matrices + n_cols - 1) // n_cols\n",
    "\n",
    "    fig, axes = plt.subplots(n_rows, n_cols, figsize=(10, 5))\n",
    "    fig.tight_layout(pad=5.0)\n",
    "\n",
    "    for i in range(n_matrices):\n",
    "        ax = axes[i // n_cols, i % n_cols]\n",
    "        cm = confusion_matrix(y_true[i], y_pred[i])\n",
    "        sns.heatmap(cm, annot=True, fmt='d', cmap=\"crest\", ax=ax)\n",
    "        ax.set_title(list(testing_stations.keys())[i])\n",
    "        ax.set_ylabel('Actual')\n",
    "        ax.set_xlabel('Predicted')\n",
    "\n",
    "    for j in range(i + 1, n_rows * n_cols):\n",
    "        axes[j // n_cols, j % n_cols].axis('off')\n",
    "\n",
    "    plt.show()\n",
    "    \n",
    "    return fig"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-13T14:25:17.380753221Z",
     "start_time": "2023-12-13T14:25:17.332015793Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "outputs": [],
   "source": [
    "training_stations = load_stations_from_path(train_path)\n",
    "testing_stations = {station.iloc[0]['station_code']: station for station in load_stations_from_path(test_path)}"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-13T14:25:19.654952401Z",
     "start_time": "2023-12-13T14:25:19.266792617Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "outputs": [],
   "source": [
    "def create_train_val_datasets(\n",
    "        dfs,\n",
    "        split_percentage,\n",
    "        feature_columns,\n",
    "        target_column,\n",
    "        sequence_length,\n",
    "        target_start_index,\n",
    "        batch_size\n",
    "):\n",
    "    total_sequences = sum(len(df) - sequence_length for df in dfs)\n",
    "\n",
    "    seq_array = np.zeros((total_sequences, sequence_length, len(feature_columns)))\n",
    "    target_array = np.zeros(total_sequences)\n",
    "\n",
    "    insert_idx = 0\n",
    "\n",
    "    for df in dfs:\n",
    "        df = preprocces(df) \n",
    "        features = df[feature_columns].values\n",
    "        targets = df[target_column].values if target_column else np.zeros(len(df))\n",
    "\n",
    "        max_index = len(df) - sequence_length\n",
    "\n",
    "        for i in range(max_index):\n",
    "            seq_array[insert_idx] = features[i:i + sequence_length]\n",
    "            target_array[insert_idx] = targets[i + sequence_length - 1]\n",
    "            insert_idx += 1\n",
    "\n",
    "    indices = np.arange(seq_array.shape[0])\n",
    "    np.random.shuffle(indices)\n",
    "    shuffled_seq_array = seq_array[indices]\n",
    "    shuffled_target_array = target_array[indices]\n",
    "\n",
    "    split_index = int(split_percentage * len(shuffled_seq_array))\n",
    "\n",
    "    train_seq = shuffled_seq_array[:split_index]\n",
    "    val_seq = shuffled_seq_array[split_index:]\n",
    "    train_target = shuffled_target_array[:split_index]\n",
    "    val_target = shuffled_target_array[split_index:]\n",
    "\n",
    "    mean = train_seq.mean(axis=(0, 1))\n",
    "    std = train_seq.std(axis=(0, 1))\n",
    "\n",
    "    train_seq = (train_seq - mean) / std\n",
    "    val_seq = (val_seq - mean) / std\n",
    "    \n",
    "    train_dataset = tf.data.Dataset.from_tensor_slices((train_seq, train_target)).cache().shuffle(buffer_size=1000).batch(batch_size).prefetch(tf.data.AUTOTUNE)\n",
    "    val_dataset = tf.data.Dataset.from_tensor_slices((val_seq, val_target)).batch(batch_size).prefetch(tf.data.AUTOTUNE)\n",
    "\n",
    "    return train_dataset, val_dataset, mean, std, len(train_seq), len(val_seq), None"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-13T14:25:19.704113475Z",
     "start_time": "2023-12-13T14:25:19.660569642Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-12-13 15:25:20 INFO 1266963494 - <module>: ======================================= Starting experiment =======================================\n",
      "2023-12-13 15:25:20 INFO 151444333 - log_parameters: SEQUENCE_LENGTH: 50\n",
      "2023-12-13 15:25:20 INFO 151444333 - log_parameters: TARGET_START_INDEX: 49\n",
      "2023-12-13 15:25:20 INFO 151444333 - log_parameters: FEATURE_COLUMNS: ['HS', 'day_sin', 'day_cos', 'month_sin', 'month_cos', 'TSS_30MIN_MEAN', 'RSWR_30MIN_MEAN', 'TA_30MIN_MEAN', 'VW_30MIN_MEAN']\n",
      "2023-12-13 15:25:20 INFO 151444333 - log_parameters: TARGET_COLUMN: no_snow\n",
      "2023-12-13 15:25:20 INFO 151444333 - log_parameters: DATE_COLUMN: measure_date\n",
      "2023-12-13 15:25:20 INFO 151444333 - log_parameters: SPLIT_PERCENTAGE: 0.8\n",
      "2023-12-13 15:25:20 INFO 151444333 - log_parameters: DATASET_BATCH_SIZE: 64\n",
      "2023-12-13 15:25:20 INFO 151444333 - log_parameters: MODEL_ARCHITECTURE: 128(l)-64-8(d)-1\n",
      "2023-12-13 15:25:20 INFO 151444333 - log_parameters: MODEL_INPUT_SHAPE: (50, 9)\n",
      "2023-12-13 15:25:20 INFO 151444333 - log_parameters: MODEL_DROPOUT_RATE: 0.5\n",
      "2023-12-13 15:25:20 INFO 151444333 - log_parameters: MODEL_OPTIMIZER: adam\n",
      "2023-12-13 15:25:20 INFO 151444333 - log_parameters: MODEL_METRICS: (['accuracy', <keras.src.metrics.confusion_metrics.Recall object at 0x7ff986a93a90>, <keras.src.metrics.confusion_metrics.Precision object at 0x7ff986a92cb0>],)\n",
      "2023-12-13 15:25:20 INFO 151444333 - log_parameters: MODEL_LOSS: binary_crossentropy\n",
      "2023-12-13 15:25:20 INFO 151444333 - log_parameters: MODEL_BATCH_SIZE: 64\n",
      "2023-12-13 15:25:20 INFO 151444333 - log_parameters: MODEL_EPOCHS: 15\n",
      "2023-12-13 15:25:20 INFO 151444333 - log_parameters: EXPERIMENT_NAME: TESTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTT\n",
      "2023-12-13 15:25:20 INFO 1266963494 - <module>: ===================================== Preparing Training Data =====================================\n",
      "2023-12-13 15:25:22 INFO 1266963494 - <module>: Training samples: 86153\n",
      "2023-12-13 15:25:22 INFO 1266963494 - <module>: Validation samples: 21539\n",
      "2023-12-13 15:25:23 INFO 1266963494 - <module>: ========================================== Fitting Model ==========================================\n",
      "Epoch 1/15\n",
      "   5/1347 [..............................] - ETA: 18s - loss: 0.6834 - accuracy: 0.4750 - recall_1: 0.9901 - precision_1: 0.3745    WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0111s vs `on_train_batch_end` time: 0.0201s). Check your callbacks.\n",
      "2023-12-13 15:25:29 WARNING callbacks - _call_batch_end_hook: Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0111s vs `on_train_batch_end` time: 0.0201s). Check your callbacks.\n",
      "1056/1347 [======================>.......] - ETA: 3s - loss: 0.1236 - accuracy: 0.9546 - recall_1: 0.9464 - precision_1: 0.9286"
     ]
    }
   ],
   "source": [
    "with mlflow.start_run(run_name=f\"{now_formatted()}_{EXPERIMENT_NAME}\"):\n",
    "    logging, tmp_log_file = setup_logger(log_file_path=log_file_path)\n",
    "    logging.info(format_with_border('Starting experiment'))\n",
    "    \n",
    "    log_parameters(logging, mlflow)\n",
    "    logging.info(format_with_border('Preparing Training Data'))\n",
    "    train_dataset, val_dataset, mean, std, num_train_samples, num_val_samples, _ = create_train_val_datasets(\n",
    "        training_stations, SPLIT_PERCENTAGE, FEATURE_COLUMNS, TARGET_COLUMN, SEQUENCE_LENGTH, TARGET_START_INDEX, DATASET_BATCH_SIZE\n",
    "    )\n",
    "    \n",
    "    mlflow_log_np_as_file(mean, 'mean')\n",
    "    mlflow_log_np_as_file(std, 'std')\n",
    "\n",
    "    logging.info(f\"Training samples: {num_train_samples}\")\n",
    "    logging.info(f\"Validation samples: {num_val_samples}\")\n",
    "    mlflow.log_param('benchmark_training_samples', num_train_samples)\n",
    "    mlflow.log_param('benchmark_validation_samples', num_val_samples)\n",
    "\n",
    "    model = create_model(MODEL_ARCHITECTURE, MODEL_INPUT_SHAPE, logging=None, dropout_rate=MODEL_DROPOUT_RATE, summary=False, dropout_layer='dropout')\n",
    "    model.compile(\n",
    "        optimizer=MODEL_OPTIMIZER,\n",
    "        metrics=MODEL_METRICS,\n",
    "        loss=MODEL_LOSS\n",
    "    )\n",
    "    \n",
    "    logging.info(format_with_border('Fitting Model'))\n",
    "    @measure_execution_time\n",
    "    def fit_model():\n",
    "        return model.fit(\n",
    "            train_dataset,\n",
    "            epochs=MODEL_EPOCHS,\n",
    "            batch_size=MODEL_BATCH_SIZE,\n",
    "            validation_data=val_dataset\n",
    "        )\n",
    "    history, elapsed_fitting_time = fit_model()\n",
    "    logging.info(f'Model fitting completed in {elapsed_fitting_time}')\n",
    "    mlflow.log_param('benchmark_model_fitting_time', elapsed_fitting_time)\n",
    "\n",
    "    logging.info(format_with_border('Evaluating Model on Test Data'))\n",
    "    test_datasets = create_test_datasets(\n",
    "        testing_stations.values(), FEATURE_COLUMNS, TARGET_COLUMN, SEQUENCE_LENGTH, TARGET_START_INDEX, DATASET_BATCH_SIZE, mean, std\n",
    "    )\n",
    "\n",
    "    all_evaluation_results = np.empty((0, 5), float)\n",
    "\n",
    "    for j, dataset in enumerate(test_datasets):\n",
    "        evaluation_results = model.evaluate(dataset, verbose=0)\n",
    "        precision = evaluation_results[2]\n",
    "        recall = evaluation_results[3]\n",
    "        f1_score = 2 * (precision * recall) / (precision + recall) if (precision + recall) != 0 else 0\n",
    "        station_name = list(testing_stations.keys())[j]\n",
    "        test_df = list(testing_stations.values())[j]\n",
    "        logging.info(\n",
    "            f'Station: {station_name}, Samples: {len(test_df)}, Loss: {evaluation_results[0]:.3f}, Accuracy: {evaluation_results[1]:.3f}, Precision: {precision:.3f}, Recall: {recall:.3f}, F1 Score: {f1_score:.3f}'\n",
    "        )\n",
    "        all_evaluation_results = np.append(all_evaluation_results, [evaluation_results + [f1_score]], axis=0)\n",
    "\n",
    "    mlflow.log_metric('test_avg_loss', np.mean(all_evaluation_results[:, 0]))\n",
    "    mlflow.log_metric('test_avg_accuracy', np.mean(all_evaluation_results[:, 1]))\n",
    "    mlflow.log_metric('test_avg_precision', np.mean(all_evaluation_results[:, 2]))\n",
    "    mlflow.log_metric('test_avg_recall', np.mean(all_evaluation_results[:, 3]))\n",
    "    mlflow.log_metric('test_avg_f1_score', np.mean(all_evaluation_results[:, 4]))\n",
    "\n",
    "    predictions = [model.predict(td, verbose=0).reshape((-1,)) > 0.5 for td in test_datasets]\n",
    "    fig = plot_data(\n",
    "        [test_station[TARGET_START_INDEX:] for test_station in testing_stations.values()],\n",
    "        predictions=predictions,\n",
    "        show=False\n",
    "    )\n",
    "    mlflow.log_figure(fig, 'prediction_results.png')\n",
    "    mlflow.log_artifact(tmp_log_file)\n",
    "    mlflow.log_figure(plot_keras_history(history), 'keras_history.png')\n",
    "    mlflow.log_figure(generate_confusion_matrix(), 'confusion_matrix.png')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-12-13T14:25:19.987414594Z"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
