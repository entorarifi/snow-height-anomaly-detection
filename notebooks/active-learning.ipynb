{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import numpy as np\n",
    "import random\n",
    "import pandas as pd\n",
    "from src.functions import create_model, plot_data, predict_with_uncertainty, create_train_val_datasets, \\\n",
    "    load_stations_from_path, create_test_datasets, create_test_dataset, check_gpus"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "2177c39661d86d19"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "check_gpus()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "c08db87e4b747ff4"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "TRAIN_PATH = '../data/labeled_daily/train'\n",
    "TEST_PATH = '../data/labeled_daily/test'\n",
    "SEQUENCE_LENGTH = 20\n",
    "TARGET_START_INDEX = SEQUENCE_LENGTH - 1\n",
    "FEATURE_COLUMNS = ['HS', 'day_sin', 'day_cos', 'month_sin', 'month_cos']\n",
    "TARGET_COLUMN = 'no_snow'\n",
    "DATE_COLUMN = 'measure_date'\n",
    "SPLIT_PERCENTAGE = 0.8\n",
    "DATASET_BATCH_SIZE = 64\n",
    "\n",
    "# Active learning\n",
    "UNCERTAINTY_ITERATIONS = 5\n",
    "\n",
    "# Model configuration\n",
    "# MODEL_ARCHITECTURE = \"128(l)-64-8(d)-1\"\n",
    "MODEL_ARCHITECTURE = \"64(l)-8(d)-1\"\n",
    "MODEL_INPUT_SHAPE = (SEQUENCE_LENGTH, len(FEATURE_COLUMNS))\n",
    "MODEL_DROPOUT_RATE = 0.5\n",
    "MODEL_OPTIMIZER = 'adam'\n",
    "MODEL_METRICS = ['accuracy']\n",
    "MODEL_LOSS = 'binary_crossentropy'\n",
    "MODEL_BATCH_SIZE = 64\n",
    "MODEL_EPOCHS = 10"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "445d4d2a9f5bf23d"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "model = create_model(MODEL_ARCHITECTURE, MODEL_INPUT_SHAPE, logging=None)\n",
    "model.compile(\n",
    "    optimizer=MODEL_OPTIMIZER,\n",
    "    metrics=MODEL_METRICS,\n",
    "    loss=MODEL_LOSS\n",
    ")\n",
    "\n",
    "training_stations = {station.iloc[0]['station_code']: station for station in load_stations_from_path(TRAIN_PATH)}\n",
    "testing_stations = {station.iloc[0]['station_code']: station for station in load_stations_from_path(TEST_PATH)}\n",
    "active_stations = [random.choice(list(training_stations.keys()))]\n",
    "summary = []\n",
    "\n",
    "for i, _ in enumerate(training_stations.items()):\n",
    "    print(f'====================================================')\n",
    "    print(f'Active Learning Iteration #{i}')\n",
    "    print(f'Current Training Stations: {active_stations}')\n",
    "\n",
    "    train_dataset, val_dataset, mean, std = create_train_val_datasets(\n",
    "        [training_stations[name] for name in active_stations],\n",
    "        SPLIT_PERCENTAGE,\n",
    "        FEATURE_COLUMNS,\n",
    "        TARGET_COLUMN,\n",
    "        SEQUENCE_LENGTH,\n",
    "        TARGET_START_INDEX,\n",
    "        DATASET_BATCH_SIZE\n",
    "    )\n",
    "\n",
    "    # print(f'Training samples: {len(current_iteration_train_df)}')\n",
    "    # print(f'Validation samples: {len(current_iteration_val_df)}')\n",
    "\n",
    "    history = model.fit(train_dataset, epochs=MODEL_EPOCHS, batch_size=MODEL_BATCH_SIZE, validation_data=val_dataset)\n",
    "\n",
    "    test_datasets = create_test_datasets(\n",
    "        testing_stations.values(), FEATURE_COLUMNS, TARGET_COLUMN, SEQUENCE_LENGTH, TARGET_START_INDEX,\n",
    "        DATASET_BATCH_SIZE, mean, std\n",
    "    )\n",
    "\n",
    "    print(f'Evaluation model on out of sample data...')\n",
    "    evaluation_results = np.array([model.evaluate(dataset) for dataset in test_datasets]).mean(axis=0)\n",
    "\n",
    "    uncertainties = {}\n",
    "\n",
    "    print(f'Calculating uncertainty scores...')\n",
    "    for station_name, station_df in training_stations.items():\n",
    "        if station_name in active_stations:\n",
    "            continue\n",
    "\n",
    "        test_dataset = create_test_dataset(\n",
    "            station_df, FEATURE_COLUMNS, TARGET_COLUMN, SEQUENCE_LENGTH, TARGET_START_INDEX, DATASET_BATCH_SIZE, mean, std\n",
    "        )\n",
    "\n",
    "        _, uncertainty_score = predict_with_uncertainty(model, test_dataset, n_iter=UNCERTAINTY_ITERATIONS)\n",
    "        uncertainties[station_name] = uncertainty_score\n",
    "\n",
    "    most_uncertain_station_name = max(uncertainties, key=uncertainties.get) if uncertainties else ''\n",
    "\n",
    "    print(f'Most uncertain {most_uncertain_station_name}')\n",
    "\n",
    "    summary.append({\n",
    "        'iteration': i,\n",
    "        'active_learning_train': active_stations,\n",
    "        'active_learning_predict': uncertainties.keys(),\n",
    "        'evaluation_results': evaluation_results,\n",
    "        'uncertainty_scores': uncertainties,\n",
    "        'most_uncertain': most_uncertain_station_name\n",
    "    })\n",
    "\n",
    "    active_stations.append(most_uncertain_station_name)\n",
    "   "
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "57025c9a429cefbb"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "predictions = [model.predict(td).reshape((-1,)) > 0.5 for td in test_datasets]\n",
    "\n",
    "plot_data(\n",
    "    [test_station[TARGET_START_INDEX:] for test_station in testing_stations.values()],\n",
    "    predictions=predictions\n",
    ")"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "6043354c381be634"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "summary = pd.DataFrame(summary)\n",
    "results_dir = '../active-learning-results/2023-11-10'\n",
    "summary.to_csv(f'{results_dir}/summary.csv', index=False)\n",
    "model.save(f'{results_dir}/model.keras')"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "initial_id"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
